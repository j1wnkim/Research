{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHRshe9Y-Q0Q"
   },
   "source": [
    "# Energy Consumption Predictions with Bayesian LSTMs in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GGWUqKU1paW"
   },
   "source": [
    "Author: Pawarit Laosunthara\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FQQioKQ-Tkr"
   },
   "source": [
    "# **Important Note for GitHub Readers:**\n",
    "Please click the **Open in Colab** button above in order to view all **interactive visualizations**.\n",
    "\n",
    "This notebook demonstrates an implementation of an (Approximate) Bayesian Recurrent Neural Network in PyTorch, originally inspired by the *Deep and Confident Prediction for Time Series at Uber* (https://arxiv.org/pdf/1709.01907.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "In this approach, Monte Carlo dropout is used to **approximate** Bayesian inference, allowing our predictions to have explicit uncertainties and confidence intervals. This property makes Bayesian Neural Networks highly appealing to critical applications requiring uncertainty quantification.\n",
    "The *Appliances energy prediction* dataset used in this example is from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction)\n",
    "\n",
    "\n",
    "**Note:** this notebook purely serves to demonstrate the implementation of Bayesian LSTMs (Long Short-Term Memory) networks in PyTorch. Therefore, extensive data exploration and feature engineering is not part of the scope of this investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psI_d17Y_3_9"
   },
   "source": [
    "# Preliminary Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFY02qDSAbqI"
   },
   "source": [
    "**Selected Columns:**\n",
    "\n",
    "For simplicity and speed when running this notebook, only temporal and autoregressive features are used.\n",
    "\n",
    "- date time year-month-day hour:minute:second, sampled every 10 minutes \\\n",
    "- Appliances, energy use in Wh for the corresponding 10-minute timestamp \\\n",
    "- day_of_week, where Monday corresponds to 0 \\\n",
    "- hour_of_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uWNK0BtB2W0E"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>BDL_tmpc</th>\n",
       "      <th>BDR_tmpc</th>\n",
       "      <th>DXR_tmpc</th>\n",
       "      <th>GON_tmpc</th>\n",
       "      <th>HFD_tmpc</th>\n",
       "      <th>HVN_tmpc</th>\n",
       "      <th>IJD_tmpc</th>\n",
       "      <th>MMK_tmpc</th>\n",
       "      <th>OXC_tmpc</th>\n",
       "      <th>SNC_tmpc</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2011 0:00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2011 1:00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.33</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2011 2:00</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.78</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>0.56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2011 3:00</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2011 4:00</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2698.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datetime  BDL_tmpc  BDR_tmpc  DXR_tmpc  GON_tmpc  HFD_tmpc  HVN_tmpc  \\\n",
       "0  1/1/2011 0:00      1.11      1.11      0.00      2.78      1.67      1.11   \n",
       "1  1/1/2011 1:00      1.11      2.22     -0.56      3.33      2.22      3.33   \n",
       "2  1/1/2011 2:00     -0.56      2.78     -1.67      3.33      2.78      2.78   \n",
       "3  1/1/2011 3:00     -1.11      2.22     -1.11      3.89      2.22      1.11   \n",
       "4  1/1/2011 4:00     -1.67      1.67     -1.11      3.33      2.22     -0.56   \n",
       "\n",
       "   IJD_tmpc  MMK_tmpc  OXC_tmpc  SNC_tmpc  Demand  \n",
       "0     -2.78     -1.67       3.0       2.0  3053.0  \n",
       "1     -2.78     -1.67       3.0       3.0  2892.0  \n",
       "2     -2.22      0.56       3.0       3.0  2774.0  \n",
       "3     -2.78      0.56       2.0       4.0  2710.0  \n",
       "4     -2.78     -1.67       4.0       5.0  2698.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/jik19004/FilesToRun/ASOS_10_CT_stations_tmpc_demand_2011_2023.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WDYp3nRh-Bpv"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "WeatherData = pd.read_csv('/home/jik19004/FilesToRun/ASOS_10_CT_stations_tmpc_demand_2011_2023.csv').drop(columns = [\"Unnamed: 0\"])\n",
    "WeatherData.ffill(inplace = True)\n",
    "WeatherData.bfill(inplace = True) # fill in missing values with the previous value.\n",
    "DateTimeCol = WeatherData[\"Datetime\"]\n",
    "HourCol = []\n",
    "WeekDayorWeekEndCol = [] \n",
    "\n",
    "for date in DateTimeCol:\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    HourCol.append(date.hour)\n",
    "    if date.weekday() < 5:\n",
    "        WeekDayorWeekEndCol.append(0)\n",
    "    else:\n",
    "        WeekDayorWeekEndCol.append(1)\n",
    "\n",
    "WeatherData.drop(columns = [\"Datetime\"], inplace = True) # drop the datetime column. \n",
    "\n",
    "\n",
    "WeatherData.insert(0, \"Hour\", HourCol)\n",
    "WeatherData.insert(1, \"Weekday or Weekend\", WeekDayorWeekEndCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for Jan 1, 2015:  35060\n",
      "index for Jan 1, 2020:  78883\n",
      "index for Jan 1, 2021:  87667\n",
      "index for Dec 31, 2022  105186\n"
     ]
    }
   ],
   "source": [
    "DateTimeCol = [datetime.strptime(date, \"%m/%d/%Y %H:%M\") for date in DateTimeCol]\n",
    "for i in range(len(DateTimeCol)):\n",
    "    date = DateTimeCol[i]\n",
    "    if int(date.year == 2015) and int(date.month) == 1 and int(date.day) == 1 and int(date.hour) == 0: # start of training\n",
    "        print(\"index for Jan 1, 2015: \", i)\n",
    "    if int(date.year) == 2020 and int(date.month) == 1 and int(date.day) == 1 and int(date.hour) == 0: # end of training \n",
    "        print(\"index for Jan 1, 2020: \", i)\n",
    "    if int(date.year) == 2021 and int(date.month) == 1 and int(date.day) == 1 and int(date.hour) == 0: # start of validation\n",
    "        print(\"index for Jan 1, 2021: \", i)\n",
    "    if int(date.year) == 2022 and int(date.month) == 12 and int(date.day) == 31 and int(date.hour) == 23: # end of validation \n",
    "        print(\"index for Dec 31, 2022 \", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add +1 to those indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YGFZFPjYGyOK"
   },
   "outputs": [],
   "source": [
    "def return_sequences(data, outputData, input_n_steps, output_n_steps):\n",
    "    X = []\n",
    "    Y = []\n",
    "    length = len(data)\n",
    "    for i in range(0,length, 1):\n",
    "        input_indx = i + input_n_steps\n",
    "        output_indx = input_indx + output_n_steps\n",
    "        if (output_indx > len(data)): # we need to have equally split sequences.\n",
    "            break               # The remaining data that cannot fit into a fixed\n",
    "                                # sequence will immediately be cut!\n",
    "        else:\n",
    "            Xsample = data.iloc[i:input_indx, :] # get the previous data\n",
    "            Ysample = outputData[input_indx:output_indx]\n",
    "            X.append(Xsample)\n",
    "            Y.append(Ysample)\n",
    "    X = np.asarray(X).astype('float64')\n",
    "    Y = np.asarray(Y).astype('float64')\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ewjMMr81GyOK"
   },
   "outputs": [],
   "source": [
    "def splitDataAndScale(data, output, split_1 = 78883, split_2 = 87667, split_3 = 105187):\n",
    "    TrainingData = (data.iloc[:split_1, :].copy())\n",
    "    TrainingCategories = TrainingData.iloc[:, [0,1]]\n",
    "    TrainingNumerical = TrainingData.iloc[:, 2:]\n",
    "    TrainingOutput = output[:split_1].copy()  \n",
    "    Scaler = StandardScaler().fit(TrainingNumerical)\n",
    "    TrainingNumerical = Scaler.transform(TrainingNumerical)\n",
    "    TrainingData = pd.concat([TrainingCategories, pd.DataFrame(TrainingNumerical)], axis = 1)\n",
    "    \n",
    "    ValidationData = data.iloc[split_2:split_3, :].copy()\n",
    "    ValidationData.reset_index(drop = True, inplace = True)\n",
    "    ValidationCategories = ValidationData.iloc[:, [0,1]]\n",
    "    ValidationNumerical = ValidationData.iloc[:, 2:]\n",
    "    ValidationNumerical = Scaler.transform(ValidationNumerical)\n",
    "    ValidationData = pd.concat([ValidationCategories, pd.DataFrame(ValidationNumerical)], axis = 1)\n",
    "    ValidationOutput = output[split_2:split_3].copy()\n",
    "    \n",
    "    TestingData = data.iloc[split_3:, :].copy()\n",
    "    TestingData.reset_index(drop = True, inplace = True)\n",
    "    TestingCategories = TestingData.iloc[:, [0,1]]\n",
    "    TestingNumerical = TestingData.iloc[:, 2:]\n",
    "    TestingNumerical = Scaler.transform(TestingNumerical)\n",
    "    TestingData = pd.concat([TestingCategories, pd.DataFrame(TestingNumerical)], axis = 1)\n",
    "    TestingOutput = output[split_3:].copy()\n",
    "\n",
    "\n",
    "    TrainingSequences = return_sequences(TrainingData, TrainingOutput, 18, 1)\n",
    "\n",
    "    TransformedTrainingData = TrainingSequences[0]\n",
    "    TransformedTrainingOutput = TrainingSequences[1]\n",
    "\n",
    "    ValidationSequences = return_sequences(ValidationData, ValidationOutput, 18, 1)\n",
    "\n",
    "    TransformedValidationData = ValidationSequences[0]\n",
    "    TransformedValidationOutput = ValidationSequences[1]\n",
    "\n",
    "    TestingSequences = return_sequences(TestingData, TestingOutput, 18, 1)\n",
    "\n",
    "    TransformedTestingData = TestingSequences[0]\n",
    "    TransformedTestingOutput = TestingSequences[1]\n",
    "\n",
    "\n",
    "    return (TransformedTrainingData, TransformedTrainingOutput, TransformedValidationData, TransformedValidationOutput,\n",
    "    TransformedTestingData, TransformedTestingOutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8BJQAqaJqv7"
   },
   "source": [
    "## Time Series Transformations\n",
    "\n",
    "1. The dataset is to be re-sampled at an hourly rate for more meaningful analytics.\n",
    "\n",
    "2. To alleviate exponential effects, the target variable is log-transformed as per the Uber paper.\n",
    "\n",
    "3. For simplicity and speed when running this notebook, only temporal and autoregressive features, namely `day_of_week`, `hour_of_day`, \\\n",
    "and previous values of `Appliances` are used as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFnQ3txg_2lj"
   },
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gUa6m83NgDn"
   },
   "source": [
    "For this example, we will use sliding windows of 10 points per each window (equivalent to 10 hours) to predict each next point. The window size can be altered via the `sequence_length` variable.\n",
    "\n",
    "Min-Max scaling has also been fitted to the training data to aid the convergence of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JSuQZkdKGyOL"
   },
   "outputs": [],
   "source": [
    "DemandData = WeatherData['Demand'].copy() # The output data\n",
    "WeatherData.drop(columns = ['Demand'], inplace = True)\n",
    "data = splitDataAndScale(WeatherData, DemandData) # splitting the data into training, validation, and testing.\n",
    "\n",
    "\n",
    "TrainingData = data[0]\n",
    "TrainingOutput = data[1]\n",
    "\n",
    "ValidationData = data[2]\n",
    "ValidationOutput = data[3]\n",
    "\n",
    "TestingData = data[4]\n",
    "TestingOutput = data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_RgEVrgWGyOL",
    "outputId": "f5305ed4-349a-4b81-b714-549f428c4e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78865, 1)\n",
      "(17502, 1)\n",
      "(8742, 1)\n"
     ]
    }
   ],
   "source": [
    "print(TrainingOutput.shape)\n",
    "print(ValidationOutput.shape)\n",
    "print(TestingOutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78865, 18, 12)\n",
      "(17502, 18, 12)\n",
      "(8742, 18, 12)\n"
     ]
    }
   ],
   "source": [
    "print(TrainingData.shape)\n",
    "print(ValidationData.shape)\n",
    "print(TestingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78865, 18, 12)\n"
     ]
    }
   ],
   "source": [
    "print(TrainingData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue1JcZm_bgsd"
   },
   "source": [
    "# Define Bayesian LSTM Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNag-wa-04WZ"
   },
   "source": [
    "To demonstrate a simple working example of the Bayesian LSTM, a model with a similar architecture and size to that in Uber's paper has been used a starting point. The network architecture is as follows:\n",
    "\n",
    "Encoder-Decoder Stage:\n",
    " - A uni-directional LSTM with 2 stacked layers & 128 hidden units acting as an encoding layer to construct a fixed-dimension embedding state\n",
    " - A uni-directional LSTM with 2 stacked layers & 32 hidden units acting as a decoding layer to produce predictions at future steps\n",
    " - Dropout is applied at **both** training and inference for both LSTM layers\n",
    "\n",
    "\n",
    " Predictor Stage:\n",
    " - 1 fully-connected output layer with 1 output (for predicting the target value) to produce a single value for the target variable\n",
    "\n",
    "\n",
    "By allowing dropout at both training and testing time, the model simulates random sampling, thus allowing varying predictions that can be used to estimate the underlying distribution of the target value, enabling explicit model uncertainties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "from typing import *\n",
    "\n",
    "\n",
    "class VariationalDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies the same dropout mask across the temporal dimension\n",
    "    See https://arxiv.org/abs/1512.05287 for more details.\n",
    "    Note that this is not applied to the recurrent activations in the LSTM like the above paper.\n",
    "    Instead, it is applied to the inputs and outputs of the recurrent layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout: float, batch_first: Optional[bool]=False):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training or self.dropout <= 0.:\n",
    "            return x\n",
    "\n",
    "        is_packed = isinstance(x, PackedSequence)\n",
    "        if is_packed:\n",
    "            x, batch_sizes = x\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = x.size(0)\n",
    "\n",
    "        # Drop same mask across entire sequence\n",
    "        if self.batch_first:\n",
    "            m = x.new_empty(max_batch_size, 1, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        else:\n",
    "            m = x.new_empty(1, max_batch_size, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        x = x.masked_fill(m == 0, 0) / (1 - self.dropout)\n",
    "\n",
    "        if is_packed:\n",
    "            return PackedSequence(x, batch_sizes)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class LSTM(nn.LSTM):\n",
    "    def __init__(self, *args, dropouti: float=0.,\n",
    "                 dropoutw: float=0., dropouto: float=0.,\n",
    "                 batch_first=True, unit_forget_bias=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs, batch_first=batch_first)\n",
    "        self.unit_forget_bias = unit_forget_bias\n",
    "        self.dropoutw = dropoutw\n",
    "        self.input_drop = VariationalDropout(dropouti,\n",
    "                                             batch_first=batch_first)\n",
    "        self.output_drop = VariationalDropout(dropouto,\n",
    "                                              batch_first=batch_first)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Use orthogonal init for recurrent layers, xavier uniform for input layers\n",
    "        Bias is 0 except for forget gate\n",
    "        \"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif \"bias\" in name and self.unit_forget_bias:\n",
    "                nn.init.zeros_(param.data)\n",
    "                param.data[self.hidden_size:2 * self.hidden_size] = 1\n",
    "\n",
    "    def _drop_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                getattr(self, name).data = \\\n",
    "                    torch.nn.functional.dropout(param.data, p=self.dropoutw,\n",
    "                                                training=self.training).contiguous()\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        self._drop_weights()\n",
    "        input = self.input_drop(input)\n",
    "        seq, state = super().forward(input, hx=hx)\n",
    "        return self.output_drop(seq), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OgWyOffPbO0b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class BayesianLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features = 12, output_length = 1, batch_size = 256, params1 = None, params2 = None, device = None):\n",
    "\n",
    "        super(BayesianLSTM, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size # user-defined\n",
    "        self.device = device \n",
    "        self.hidden_size_1 = params1[0] # number of encoder cells (from paper)\n",
    "        self.hidden_size_2 = params1[1] # number of decoder cells (from paper)\n",
    "        self.stacked_layers = 1 # number of (stacked) LSTM layers for each stage\n",
    "        self.num_layers = params1[2] # number of layers. \n",
    "        self.dropout_probability = params1[3] # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
    "\n",
    "        \n",
    "        layers = [] \n",
    "        input_size = self.hidden_size_2\n",
    "        \n",
    "        self.lstm1 = LSTM(input_size = n_features, hidden_size = self.hidden_size_1, num_layers = self.stacked_layers, dropouti = self.dropout_probability,\n",
    "                               dropoutw = self.dropout_probability, dropouto = self.dropout_probability)\n",
    "        self.lstm2 = LSTM(input_size = self.hidden_size_1, hidden_size = self.hidden_size_2, num_layers = self.stacked_layers, dropouti = self.dropout_probability,\n",
    "                               dropoutw = self.dropout_probability, dropouto = self.dropout_probability)\n",
    "        for i in range(0, self.num_layers):\n",
    "            num_units = params2[i]\n",
    "            layers.append(nn.Linear(input_size, num_units, bias = True))\n",
    "            if i!= self.num_layers -1:\n",
    "               layers.append(torch.nn.BatchNorm1d(num_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            input_size = num_units\n",
    "        \n",
    "        \n",
    "        self.intermediate_layers = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(input_size, output_length)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x[0])\n",
    "        output = x[0]\n",
    "        output = output[:, -1, :] # take the last decoder cell's outputs\n",
    "        \n",
    "        output = self.intermediate_layers(output)\n",
    "        y_pred = self.fc(output)\n",
    "        \n",
    "        return y_pred\n",
    "                \n",
    "    def loss(self, pred, truth):\n",
    "        \n",
    "        return self.loss_fn(pred, truth)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ8JLm-ShlaU"
   },
   "source": [
    "### Begin Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "015pu48r3X1F"
   },
   "source": [
    "To train the Bayesian LSTM, we use the ADAM optimizer along with mini-batch gradient descent (`batch_size = 128`). For quick demonstration purposes, the model is trained for 150 epochs.\n",
    "\n",
    "The Bayesian LSTM is trained on the first 70% of data points, using the aforementioned sliding windows of size 10. The remaining 30% of the dataset is held out purely for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iZ__nxaCzZE",
    "outputId": "915e737a-6235-4842-b7fe-e94648a86cfb"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, output):\n",
    "        data = torch.tensor(data).float();\n",
    "        output = torch.tensor(output).float()\n",
    "        self.data = data\n",
    "        self.output = output;\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx];\n",
    "        y = self.output[idx];\n",
    "\n",
    "        return x, y;\n",
    "\n",
    "# use the past 72 hours in advance and then predict the 1st hour, 6th hour, 12 hours!\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item() * target.size(0)\n",
    "    return running_loss / len(val_loader.dataset)\n",
    "\n",
    "def Train_and_Evaluate(train_loader, val_loader, device, params1, params2, numEpochs, early_stop_epochs):\n",
    "    model = BayesianLSTM(params1 = params1, params2 = params2, device = device)\n",
    "    model = model.to(device);\n",
    "    LossFunction = torch.nn.L1Loss();\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "\n",
    "\n",
    "    Optimizer = torch.optim.Adam(params = model.parameters())\n",
    "    for epoch in range(0,numEpochs):\n",
    "        model.train()\n",
    "        Training_Loss = 0;\n",
    "        total_samples = 0;\n",
    "        for input, output in train_loader:\n",
    "            input = input.to(device);\n",
    "            output = torch.squeeze(output, 1);\n",
    "            output = output.to(device);\n",
    "            predictedVal = model(input)\n",
    "            predictedVal = torch.squeeze(predictedVal, 1)\n",
    "            Optimizer.zero_grad();\n",
    "            batchLoss = LossFunction(predictedVal, output);\n",
    "            batchLoss.backward();\n",
    "            Optimizer.step();\n",
    "            Training_Loss += batchLoss * output.size(0) #* output.size(0);\n",
    "            total_samples += output.size(0)\n",
    "        Training_Loss = Training_Loss.item()/total_samples\n",
    "\n",
    "\n",
    "        Validation_Loss = 0;\n",
    "        print(\"passed \", epoch, \"epoch\", \"Training Loss: \", Training_Loss,\" \", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_val_samples = 0;\n",
    "            Validation_Loss = 0;\n",
    "            for val_input, val_output in val_loader:\n",
    "                val_input = val_input.to(device);\n",
    "                val_output = torch.squeeze(val_output,1);\n",
    "                val_output = val_output.to(device);\n",
    "                predictedVal = model(val_input)\n",
    "                predictedVal = torch.squeeze(predictedVal, 1)\n",
    "                Validation_Loss += LossFunction(val_output, predictedVal) * val_output.size(0)\n",
    "                total_val_samples += val_output.size(0)\n",
    "            Validation_Loss = Validation_Loss/total_val_samples\n",
    "            print(\"Validation Loss: \", Validation_Loss)\n",
    "\n",
    "            if Validation_Loss < best_val_loss:\n",
    "                best_val_loss = Validation_Loss\n",
    "                torch.save(model, \"/home/jik19004/FilesToRun/BayesianLSTM20/BayesianLSTM20\")\n",
    "                early_stop_count = 0;   \n",
    "            else:\n",
    "                early_stop_count +=1\n",
    "            if early_stop_count >= early_stop_epochs:\n",
    "                return best_val_loss;\n",
    "    return best_val_loss;\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    #model.eval()\n",
    "    predictions = []\n",
    "    act_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            act_outputs.append(_.numpy())\n",
    "\n",
    "    return (np.concatenate(predictions), np.concatenate(act_outputs))\n",
    "\n",
    "\n",
    "def predict2(model, data_loader, device):\n",
    "    #model.eval()\n",
    "    predictions = []\n",
    "    act_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            data = data.to(device)\n",
    "            output = predict_with_dropout(model, data, device)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            act_outputs.append(_.numpy())\n",
    "\n",
    "    return (np.concatenate(predictions), np.concatenate(act_outputs))\n",
    "\n",
    "\n",
    "def predict_with_dropout(model, input_tensor, device):\n",
    "    # Set the model to evaluation mode initially\n",
    "    model.eval()\n",
    "    # Manually enable dropout layers and ensure batchnorm layers are in eval mode\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Dropout):\n",
    "            module.train()  # Enable dropout\n",
    "        elif isinstance(module, torch.nn.BatchNorm1d) or isinstance(module, torch.nn.BatchNorm2d) or isinstance(module, torch.nn.BatchNorm3d):\n",
    "            module.eval()  # Ensure batchnorm is in eval mode\n",
    "    \n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        output = model(input_tensor)  # Add batch dimension if necessary\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_and_Evaluate2(train_loader, val_loader, device, params1, params2, numEpochs, early_stop_epochs):\n",
    "    #num_layers, input_dim, hidden_unit1, hidden_unit2, output_unit, lastNeurons, batch_size, params, device = None\n",
    "    model = BayesianLSTM(params1 = params1, params2 = params2, device = device)\n",
    "    model = model.to(device);\n",
    "    TrainEpochLoss = [] \n",
    "    ValidationEpochLoss = [] \n",
    "    LossFunction = torch.nn.L1Loss();\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "\n",
    "\n",
    "    Optimizer = torch.optim.Adam(params = model.parameters())\n",
    "    for epoch in range(0,numEpochs):\n",
    "        model.train()\n",
    "        Training_Loss = 0;\n",
    "        total_samples = 0;\n",
    "        for input, output in train_loader:\n",
    "            input = input.to(device);\n",
    "            output = torch.squeeze(output, 1);\n",
    "            output = output.to(device);\n",
    "            predictedVal = model(input)\n",
    "            predictedVal = torch.squeeze(predictedVal, 1)\n",
    "            Optimizer.zero_grad();\n",
    "            batchLoss = LossFunction(predictedVal, output);\n",
    "            batchLoss.backward();\n",
    "            Optimizer.step();\n",
    "            Training_Loss += batchLoss * output.size(0) #* output.size(0);\n",
    "            total_samples += output.size(0)\n",
    "        Training_Loss = Training_Loss.item()/total_samples\n",
    "        TrainEpochLoss.append(Training_Loss)\n",
    "\n",
    "\n",
    "        Validation_Loss = 0;\n",
    "        print(\"passed \", epoch, \"epoch\", \"Training Loss: \", Training_Loss,\" \", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_val_samples = 0;\n",
    "            Validation_Loss = 0;\n",
    "            for val_input, val_output in val_loader:\n",
    "                val_input = val_input.to(device);\n",
    "                val_output = torch.squeeze(val_output,1);\n",
    "                val_output = val_output.to(device);\n",
    "                predictedVal = model(val_input)\n",
    "                predictedVal = torch.squeeze(predictedVal, 1)\n",
    "                Validation_Loss += LossFunction(val_output, predictedVal) * val_output.size(0)\n",
    "                total_val_samples += val_output.size(0)\n",
    "            Validation_Loss = Validation_Loss.item()/total_val_samples\n",
    "            print(\"Validation Loss: \", Validation_Loss)\n",
    "            ValidationEpochLoss.append(Validation_Loss)\n",
    "\n",
    "            if Validation_Loss < best_val_loss:\n",
    "                best_val_loss = Validation_Loss\n",
    "                torch.save(model, \"/home/jik19004/FilesToRun/BayesianLSTM20/BayesianLSTM20\")\n",
    "                early_stop_count = 0;   \n",
    "            else:\n",
    "                early_stop_count +=1\n",
    "            if early_stop_count >= early_stop_epochs:\n",
    "                return (TrainEpochLoss, ValidationEpochLoss);\n",
    "    return (TrainEpochLoss, ValidationEpochLoss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "M9m5DLiAGyOO"
   },
   "outputs": [],
   "source": [
    "TrainingData = TimeSeriesDataset(np.array(TrainingData),np.array(TrainingOutput));\n",
    "TrainingLoader = DataLoader(TrainingData, batch_size = 256);\n",
    "\n",
    "\n",
    "ValidationData = TimeSeriesDataset(ValidationData, ValidationOutput); ### Set it with the previous validation data\n",
    "ValidationLoader = DataLoader(ValidationData, batch_size = 256);\n",
    "\n",
    "\n",
    "TestingData = TimeSeriesDataset(TestingData,TestingOutput); ### Set it with the previous testing data.\n",
    "TestingLoader = DataLoader(TestingData, batch_size = 256);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianLSTM(\n",
      "  (lstm1): LSTM(\n",
      "    12, 214, batch_first=True\n",
      "    (input_drop): VariationalDropout()\n",
      "    (output_drop): VariationalDropout()\n",
      "  )\n",
      "  (lstm2): LSTM(\n",
      "    214, 172, batch_first=True\n",
      "    (input_drop): VariationalDropout()\n",
      "    (output_drop): VariationalDropout()\n",
      "  )\n",
      "  (intermediate_layers): Sequential(\n",
      "    (0): Linear(in_features=172, out_features=144, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=144, out_features=1, bias=True)\n",
      "  (loss_fn): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"/home/jik19004/FilesToRun/BayesianLSTM20/BayesianLSTM20(BEST_SHUFFLE)\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCrnRRfnGyOO",
    "outputId": "2d512125-f70e-42f3-c296-a09c4c23bb80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-15 10:43:45,754]\u001b[0m Using an existing study with name 'NewLSTMBayesian20' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#num_layers, hidden_unit1, hidden_unit2, lastNeurons, batch_size, params, device = None\n",
    "def objective(trial):\n",
    "    params1 = [trial.suggest_int(\"LSTM_neurons1\", low = 158, high = 256, step = 14),\n",
    "               trial.suggest_int(\"LSTM_neurons2\", low = 158, high = 256, step = 14),\n",
    "              trial.suggest_int(\"num_layers\", low = 1, high = 4, step = 1), \n",
    "              trial.suggest_float(\"dropout_prob\", low = 0.12, high = 0.2, log = True)]\n",
    "    params2 = [trial.suggest_int(\"num_hiddenZero\", low = 72, high = 180, step = 36),\n",
    "               trial.suggest_int(\"num_hiddenOne\", low = 72, high = 180, step = 36),\n",
    "               trial.suggest_int(\"num_hiddenTwo\", low = 58, high = 154, step = 24),\n",
    "               trial.suggest_int(\"num_hiddenThree\", low = 58, high = 154, step = 24)]\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n",
    "    return Train_and_Evaluate(TrainingLoader, ValidationLoader, device, params1, params2, 2000, 150); \n",
    "\n",
    "\n",
    "import joblib\n",
    "study_name = 'sqlite:///LSTMBayesianOutput20.db'\n",
    "study = optuna.create_study(direction = \"minimize\", sampler = optuna.samplers.TPESampler(), study_name = \"NewLSTMBayesian20\", load_if_exists = True, storage = 'sqlite:///LSTMBayesianOutput20.db')\n",
    "#study.optimize(objective, n_trials = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11438/1256677621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \"\"\"\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             )\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/storages/_cached_storage.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrozenTrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     def set_trial_state_values(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    936\u001b[0m                 \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_max_value_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                 \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_min_value_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mtrial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/storages/_rdb/models.py\u001b[0m in \u001b[0;36mfind_min_value_trial\u001b[0;34m(cls, study_id, objective, session)\u001b[0m\n\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOT_FOUND_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Record does not exist."
     ]
    }
   ],
   "source": [
    "study.best_params\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = [study.best_params[\"LSTM_neurons1\"], study.best_params[\"LSTM_neurons2\"], study.best_params[\"num_layers\"], study.best_params[\"dropout_prob\"]]\n",
    "params2 = [study.best_params[\"num_hiddenZero\"], study.best_params[\"num_hiddenOne\"], study.best_params[\"num_hiddenTwo\"], study.best_params[\"num_hiddenThree\"]]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n",
    "#best_val_loss = Train_and_Evaluate2(TrainingLoader, ValidationLoader, device, params1, params2, 2000, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "q-JWl1d3GyOP",
    "outputId": "e8ee81b7-b2f8-4bc9-b872-ddfd6bc44846"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 10:12:48.962422: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-07 10:12:48.999766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-07 10:12:49.803626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Testing:  140852.48\n",
      "MAE for Testing:  295.00555\n",
      "MAPE for Testing:  tensor(0.1024)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "model = torch.load(\"/home/jik19004/FilesToRun/BayesianLSTM20/BayesianLSTM20(BEST_SHUFFLE)\")\n",
    "predictions = predict(model, TestingLoader, device = torch.device(\"cuda\"))\n",
    "MAE_result = mean_absolute_error(predictions[0], predictions[1])\n",
    "MSE_result = mean_squared_error(predictions[0], predictions[1])\n",
    "MAPE = MeanAbsolutePercentageError() \n",
    "MAPE_result = MAPE(torch.Tensor(predictions[0]), torch.Tensor(predictions[1]))\n",
    "print(\"MSE for Testing: \", MSE_result)\n",
    "print(\"MAE for Testing: \", MAE_result)\n",
    "print(\"MAPE for Testing: \", MAPE_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation:  242.88213\n",
      "MAPE for Validation:  tensor(0.0790)\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(model, ValidationLoader, device = torch.device(\"cuda\"))\n",
    "MAE_result = mean_absolute_error(predictions[0], predictions[1])\n",
    "MAPE = MeanAbsolutePercentageError()\n",
    "MAPE_result = MAPE(torch.Tensor(predictions[0]), torch.Tensor(predictions[1]))\n",
    "\n",
    "print(\"MAE for Validation: \", MAE_result)\n",
    "print(\"MAPE for Validation: \", MAPE_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Training:  239.87048\n",
      "MAPE for Training:  tensor(0.0687)\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(model, TrainingLoader, device = torch.device(\"cuda\"))\n",
    "MAE_result = mean_absolute_error(predictions[0], predictions[1])\n",
    "MAPE = MeanAbsolutePercentageError()\n",
    "MAPE_result = MAPE(torch.Tensor(predictions[0]), torch.Tensor(predictions[1]))\n",
    "\n",
    "\n",
    "print(\"MAE for Training: \", MAE_result)\n",
    "print(\"MAPE for Training: \", MAPE_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_val_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m TrainEpochLoss \u001b[38;5;241m=\u001b[39m \u001b[43mbest_val_loss\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m ValidationEpochLoss \u001b[38;5;241m=\u001b[39m best_val_loss[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_val_loss' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "TrainEpochLoss = best_val_loss[0]\n",
    "ValidationEpochLoss = best_val_loss[1]\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0,0,1.7,1.25])\n",
    "axes.plot(TrainEpochLoss, label = \"Training Loss\")\n",
    "axes.plot(ValidationEpochLoss, label = \"Validation Loss\")\n",
    "axes.set_yticks(np.arange(0, 3000, 200))\n",
    "axes.set_title(\"Training and Validation Loss for Bayesian LSTM\")\n",
    "axes.set_xlabel(\"Epochs\")\n",
    "axes.set_ylabel(\"Loss: Mean Absolute Error\")\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUS459C6ro22"
   },
   "source": [
    "# Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGYj2vTl311y"
   },
   "source": [
    "The Bayesian LSTM implemented is shown to produce reasonably accurate and sensible results on both the training and test sets, often comparable to other existing frequentist machine learning and deep learning methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>BDL_tmpc</th>\n",
       "      <th>BDR_tmpc</th>\n",
       "      <th>DXR_tmpc</th>\n",
       "      <th>GON_tmpc</th>\n",
       "      <th>HFD_tmpc</th>\n",
       "      <th>HVN_tmpc</th>\n",
       "      <th>IJD_tmpc</th>\n",
       "      <th>MMK_tmpc</th>\n",
       "      <th>OXC_tmpc</th>\n",
       "      <th>SNC_tmpc</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2011 0:00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3053.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2011 1:00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.33</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2892.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2011 2:00</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.78</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>0.56</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2774.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2011 3:00</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2710.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2011 4:00</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2698.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113942</th>\n",
       "      <td>12/31/2023 19:00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>4.44</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3407.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113943</th>\n",
       "      <td>12/31/2023 20:00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3231.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113944</th>\n",
       "      <td>12/31/2023 21:00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3095.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113945</th>\n",
       "      <td>12/31/2023 22:00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2937.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113946</th>\n",
       "      <td>12/31/2023 23:00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2791.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113947 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Datetime  BDL_tmpc  BDR_tmpc  DXR_tmpc  GON_tmpc  HFD_tmpc  \\\n",
       "0          1/1/2011 0:00      1.11      1.11      0.00      2.78      1.67   \n",
       "1          1/1/2011 1:00      1.11      2.22     -0.56      3.33      2.22   \n",
       "2          1/1/2011 2:00     -0.56      2.78     -1.67      3.33      2.78   \n",
       "3          1/1/2011 3:00     -1.11      2.22     -1.11      3.89      2.22   \n",
       "4          1/1/2011 4:00     -1.67      1.67     -1.11      3.33      2.22   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "113942  12/31/2023 19:00      2.22      4.44      3.33      3.33      3.33   \n",
       "113943  12/31/2023 20:00      2.22      3.89      2.78      3.33      3.33   \n",
       "113944  12/31/2023 21:00      2.22      3.89      3.33      3.33      3.33   \n",
       "113945  12/31/2023 22:00      1.67      3.89      2.78      2.78      3.33   \n",
       "113946  12/31/2023 23:00      1.67      3.89      2.78      3.33      3.33   \n",
       "\n",
       "        HVN_tmpc  IJD_tmpc  MMK_tmpc  OXC_tmpc  SNC_tmpc    Demand  \n",
       "0           1.11     -2.78     -1.67      3.00       2.0  3053.000  \n",
       "1           3.33     -2.78     -1.67      3.00       3.0  2892.000  \n",
       "2           2.78     -2.22      0.56      3.00       3.0  2774.000  \n",
       "3           1.11     -2.78      0.56      2.00       4.0  2710.000  \n",
       "4          -0.56     -2.78     -1.67      4.00       5.0  2698.000  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "113942      3.89      1.67      2.22      1.11       2.0  3407.766  \n",
       "113943      3.89      1.67      1.67      1.11       2.0  3231.547  \n",
       "113944      4.44      1.11      1.67      0.56       2.0  3095.179  \n",
       "113945      4.44      1.11      1.67      0.56       2.0  2937.253  \n",
       "113946      4.44      0.56      1.67      0.56       2.0  2791.655  \n",
       "\n",
       "[113947 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('/home/jik19004/FilesToRun/ASOS_10_CT_stations_tmpc_demand_2011_2023.csv').drop(columns = [\"Unnamed: 0\"])\n",
    "x.ffill(inplace = True)\n",
    "x.bfill(inplace = True) # fill in missing values with the previous value.\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iERCnyhqGyOP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "x = pd.read_csv(\"/home/jik19004/FilesToRun/ASOS_10_CT_stations_tmpc_demand_2011_2023.csv\")[\"Datetime\"]\n",
    "dateList = []\n",
    "for i in range(len(x)): ## just create the datetimes so that we can use it for graph plotting.\n",
    "    dateList.append(datetime.strptime(x[i], \"%m/%d/%Y %H:%M\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "efoE_qxFGyOP",
    "outputId": "812668ef-98f3-466b-e21c-af213b1bf00f"
   },
   "outputs": [],
   "source": [
    "x = np.array(pd.read_csv(\"/home/jik19004/FilesToRun/ASOS_10_CT_stations_tmpc_demand_2011_2023.csv\")[\"Demand\"])\n",
    "x = pd.DataFrame({\"DateTime\": dateList, \"Demand\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "07qm7YlwGyOP"
   },
   "outputs": [],
   "source": [
    "training_df = x.iloc[:78883, :]\n",
    "validation_df = x.iloc[87667:105187, :]\n",
    "testing_df = x.iloc[105187:, :] #splits for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jrwiy646yq7t"
   },
   "source": [
    "# Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FEzMrU147zx"
   },
   "source": [
    "The fact that stochastic dropouts are applied after each LSTM layer in the Bayesian LSTM enables users to interpret the model outputs as random samples from the posterior distribution of the target variable.\n",
    "\n",
    "This implies that by running multiple experiments/predictions, can approximate  parameters of the posterioir distribution, namely the mean and the variance, in order to create confidence intervals for each prediction.\n",
    "\n",
    "In this example, we construct 99% confidence intervals that are three standard deviations away from the approximate mean of each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PT7jTMoqGyOQ",
    "outputId": "89a6ddd3-33df-4804-dbec-bf511e3ec38f"
   },
   "outputs": [],
   "source": [
    "bayesian_lstm = torch.load(\"/home/jik19004/FilesToRun/BayesianLSTM20/BayesianLSTM20(BEST_SHUFFLE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3B5Vbkn-GyOQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    }
   ],
   "source": [
    "TrainingPredictions, _ = predict(bayesian_lstm, TrainingLoader, torch.device(\"cuda\"))\n",
    "ValidationPredictions, _ = predict(bayesian_lstm, ValidationLoader, torch.device(\"cuda\"))\n",
    "TestingPredictions, _ = predict(bayesian_lstm, TestingLoader, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>3053.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>2892.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>2774.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>2710.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>2698.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113942</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>3407.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113943</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>3231.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113944</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>3095.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113945</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>2937.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113946</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>2791.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113947 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DateTime    Demand\n",
       "0      2011-01-01 00:00:00  3053.000\n",
       "1      2011-01-01 01:00:00  2892.000\n",
       "2      2011-01-01 02:00:00  2774.000\n",
       "3      2011-01-01 03:00:00  2710.000\n",
       "4      2011-01-01 04:00:00  2698.000\n",
       "...                    ...       ...\n",
       "113942 2023-12-31 19:00:00  3407.766\n",
       "113943 2023-12-31 20:00:00  3231.547\n",
       "113944 2023-12-31 21:00:00  3095.179\n",
       "113945 2023-12-31 22:00:00  2937.253\n",
       "113946 2023-12-31 23:00:00  2791.655\n",
       "\n",
       "[113947 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KBJDyf2fGyOQ"
   },
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame()\n",
    "validation_df = pd.DataFrame()\n",
    "testing_df = pd.DataFrame()\n",
    "\n",
    "training_df[\"Date\"] = x.iloc[18:78883, 0]\n",
    "training_df[\"Actual Train Output\"] = x.iloc[18:78883, 1]\n",
    "training_df[\"Predicted Train Output\"] = TrainingPredictions\n",
    "\n",
    "validation_df[\"Date\"] = x.iloc[87667+18:105187,0]\n",
    "validation_df[\"Actual Val Output\"] = x.iloc[87667+18:105187, 1]\n",
    "validation_df[\"Predicted Val Output\"] = ValidationPredictions\n",
    "\n",
    "testing_df[\"Date\"] = x.iloc[105187 + 18 :, 0]\n",
    "testing_df[\"Actual Test Output\"] = x.iloc[105187 + 18:, 1]\n",
    "testing_df[\"Predicted Test Output\"] = TestingPredictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Jb4xyVW6DVUV",
    "outputId": "110ad77c-1090-43bb-83c0-15a099209a13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_24298/1295371197.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 500\n",
    "\n",
    "\n",
    "test_uncertainty_df = pd.DataFrame()\n",
    "test_uncertainty_df['Date'] = testing_df['Date']\n",
    "\n",
    "\n",
    "for i in range(n_experiments):\n",
    "  experiment_predictions, _ = predict2(bayesian_lstm, TestingLoader, torch.device(\"cuda\"))\n",
    "  test_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
    "\n",
    "\n",
    "energy_consumption_df = test_uncertainty_df.filter(like='energy_demand', axis=1)\n",
    "test_uncertainty_df2 = test_uncertainty_df.copy() # copy and creat a duplicate of the dataframe. \n",
    "\n",
    "test_uncertainty_df['energy_demand_mean'] = energy_consumption_df.mean(axis=1)\n",
    "test_uncertainty_df['energy_demand_std'] = energy_consumption_df.std(axis=1)\n",
    "\n",
    "test_uncertainty_df = test_uncertainty_df[['Date', 'energy_demand_mean', 'energy_demand_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_uncertainty_df2.to_csv(\"Testing500.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jHRALjusGyOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.67375896835594\n",
      "tensor(0.0892)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(test_uncertainty_df['energy_demand_mean'])\n",
    "actualVals = np.array(testing_df[\"Actual Test Output\"])\n",
    "\n",
    "error = mean_absolute_error(arr, actualVals)\n",
    "mape_error = MAPE(torch.Tensor(arr), torch.Tensor(actualVals))\n",
    "\n",
    "print(error)\n",
    "print(mape_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/1887955909.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 500\n",
    "\n",
    "\n",
    "validation_uncertainty_df = pd.DataFrame()\n",
    "validation_uncertainty_df['Date'] = validation_df['Date']\n",
    "\n",
    "\n",
    "for i in range(n_experiments):\n",
    "  experiment_predictions, _ = predict2(bayesian_lstm, ValidationLoader, torch.device(\"cuda\"))\n",
    "  validation_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
    "\n",
    "\n",
    "energy_consumption_df = validation_uncertainty_df.filter(like='energy_demand', axis=1)\n",
    "validation_uncertainty_df2 = validation_uncertainty_df.copy() # copy and creat a duplicate of the dataframe. \n",
    "\n",
    "validation_uncertainty_df['energy_demand_mean'] = energy_consumption_df.mean(axis=1)\n",
    "validation_uncertainty_df['energy_demand_std'] = energy_consumption_df.std(axis=1)\n",
    "\n",
    "validation_uncertainty_df = validation_uncertainty_df[['Date', 'energy_demand_mean', 'energy_demand_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_uncertainty_df2.to_csv(\"Validation500.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.00509938082968\n",
      "tensor(0.0606)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(validation_uncertainty_df['energy_demand_mean'])\n",
    "actualVals = np.array(validation_df[\"Actual Val Output\"])\n",
    "\n",
    "error = mean_absolute_error(arr, actualVals)\n",
    "mape_error = MAPE(torch.Tensor(arr), torch.Tensor(actualVals))\n",
    "\n",
    "print(error)\n",
    "print(mape_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
      "/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "/tmp/ipykernel_11438/2786918693.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 500\n",
    "\n",
    "\n",
    "training_uncertainty_df = pd.DataFrame()\n",
    "training_uncertainty_df['Date'] = training_df['Date']\n",
    "\n",
    "\n",
    "for i in range(n_experiments):\n",
    "  experiment_predictions, _ = predict(bayesian_lstm, TrainingLoader, torch.device(\"cuda\"))\n",
    "  training_uncertainty_df['energy_demand_{}'.format(i)] = experiment_predictions\n",
    "\n",
    "\n",
    "energy_consumption_df = training_uncertainty_df.filter(like='energy_demand', axis=1)\n",
    "training_uncertainty_df2 = training_uncertainty_df.copy() # copy and creat a duplicate of the dataframe. \n",
    "\n",
    "training_uncertainty_df['energy_demand_mean'] = energy_consumption_df.mean(axis=1)\n",
    "training_uncertainty_df['energy_demand_std'] = energy_consumption_df.std(axis=1)\n",
    "\n",
    "training_uncertainty_df = training_uncertainty_df[['Date', 'energy_demand_mean', 'energy_demand_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_uncertainty_df2.to_csv(\"Training500.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.33682564580792\n",
      "tensor(0.0520)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(training_uncertainty_df['energy_demand_mean'])\n",
    "actualVals = np.array(training_df[\"Actual Train Output\"])\n",
    "\n",
    "error = mean_absolute_error(arr, actualVals)\n",
    "mape_error = MAPE(torch.Tensor(arr), torch.Tensor(actualVals))\n",
    "\n",
    "print(error)\n",
    "print(mape_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNrb70dSdDH0"
   },
   "outputs": [],
   "source": [
    "test_uncertainty_df['95% lower_bound'] = test_uncertainty_df['energy_demand_mean'] - 1.645*test_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "test_uncertainty_df['95% upper_bound'] = test_uncertainty_df['energy_demand_mean'] + 1.645*test_uncertainty_df['energy_demand_std'] #99 % confidene interval\n",
    "\n",
    "test_uncertainty_df[\"99.99% lower_bound\"] = test_uncertainty_df[\"energy_demand_mean\"] - 3 * test_uncertainty_df[\"energy_demand_std\"]\n",
    "test_uncertainty_df[\"99.99% upper_bound\"] = test_uncertainty_df[\"energy_demand_mean\"] + 3 * test_uncertainty_df[\"energy_demand_std\"]\n",
    "\n",
    "test_uncertainty_df[\"99.999% lower_bound\"] = test_uncertainty_df[\"energy_demand_mean\"] - 3.3 * test_uncertainty_df[\"energy_demand_std\"]\n",
    "test_uncertainty_df[\"99.999% upper_bound\"] = test_uncertainty_df[\"energy_demand_mean\"] + 3.3 * test_uncertainty_df[\"energy_demand_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "WdHylS8OdEHt",
    "outputId": "a366f060-d302-40e9-d065-19cdefcbddfb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "99 Upper C.I. Bound",
         "type": "scatter",
         "x": [
          "2023-02-02T01:00:00",
          "2023-02-02T02:00:00",
          "2023-02-02T03:00:00",
          "2023-02-02T04:00:00",
          "2023-02-02T05:00:00",
          "2023-02-02T06:00:00",
          "2023-02-02T07:00:00",
          "2023-02-02T08:00:00",
          "2023-02-02T09:00:00",
          "2023-02-02T10:00:00",
          "2023-02-02T11:00:00",
          "2023-02-02T12:00:00",
          "2023-02-02T13:00:00",
          "2023-02-02T14:00:00",
          "2023-02-02T15:00:00",
          "2023-02-02T16:00:00",
          "2023-02-02T17:00:00",
          "2023-02-02T18:00:00",
          "2023-02-02T19:00:00",
          "2023-02-02T20:00:00",
          "2023-02-02T21:00:00",
          "2023-02-02T22:00:00",
          "2023-02-02T23:00:00",
          "2023-02-03T00:00:00",
          "2023-02-03T01:00:00",
          "2023-02-03T02:00:00",
          "2023-02-03T03:00:00",
          "2023-02-03T04:00:00",
          "2023-02-03T05:00:00",
          "2023-02-03T06:00:00",
          "2023-02-03T07:00:00",
          "2023-02-03T08:00:00",
          "2023-02-03T09:00:00",
          "2023-02-03T10:00:00",
          "2023-02-03T11:00:00",
          "2023-02-03T12:00:00",
          "2023-02-03T13:00:00",
          "2023-02-03T14:00:00",
          "2023-02-03T15:00:00",
          "2023-02-03T16:00:00",
          "2023-02-03T17:00:00",
          "2023-02-03T18:00:00",
          "2023-02-03T19:00:00",
          "2023-02-03T20:00:00",
          "2023-02-03T21:00:00",
          "2023-02-03T22:00:00",
          "2023-02-03T23:00:00",
          "2023-02-04T00:00:00",
          "2023-02-04T01:00:00",
          "2023-02-04T02:00:00",
          "2023-02-04T03:00:00",
          "2023-02-04T04:00:00",
          "2023-02-04T05:00:00",
          "2023-02-04T06:00:00",
          "2023-02-04T07:00:00",
          "2023-02-04T08:00:00",
          "2023-02-04T09:00:00",
          "2023-02-04T10:00:00",
          "2023-02-04T11:00:00",
          "2023-02-04T12:00:00",
          "2023-02-04T13:00:00",
          "2023-02-04T14:00:00",
          "2023-02-04T15:00:00",
          "2023-02-04T16:00:00",
          "2023-02-04T17:00:00",
          "2023-02-04T18:00:00",
          "2023-02-04T19:00:00",
          "2023-02-04T20:00:00",
          "2023-02-04T21:00:00",
          "2023-02-04T22:00:00",
          "2023-02-04T23:00:00"
         ],
         "y": [
          3469.1669921875,
          3544.45458984375,
          3550.496826171875,
          3608.80810546875,
          3870.0478515625,
          4389.7548828125,
          4636.31787109375,
          4655.67236328125,
          4495.1865234375,
          4444.0986328125,
          4382.64794921875,
          4321.0615234375,
          4232.90966796875,
          4243.0498046875,
          4287.53125,
          4535.4091796875,
          4831.01611328125,
          4894.41015625,
          4815.53662109375,
          4605.61083984375,
          4396.015625,
          4068.855224609375,
          3714.94287109375,
          3472.34765625,
          3242.962158203125,
          3221.199951171875,
          3204.552978515625,
          3269.54248046875,
          3445.79248046875,
          3870.50390625,
          4353.9736328125,
          4538.21484375,
          4645.33984375,
          4729.302734375,
          4759.0986328125,
          4768.2802734375,
          4784.2373046875,
          4850.9140625,
          4910.6044921875,
          5205.29248046875,
          5466.52685546875,
          5613.42138671875,
          5514.78125,
          5392.36181640625,
          5199.54150390625,
          4910.412109375,
          4543.8095703125,
          4442.337890625,
          4240.0859375,
          4214.02490234375,
          4230.78173828125,
          4309.12158203125,
          4385.2333984375,
          4569.146484375,
          4808.16552734375,
          5123.1962890625,
          5208.9921875,
          5261.5439453125,
          5140.2041015625,
          5096.0205078125,
          5025.12841796875,
          4954.9853515625,
          5028.76806640625,
          5283.1630859375,
          5364.4013671875,
          5375.31884765625,
          5335.5634765625,
          5145.09326171875,
          4859.93310546875,
          4463.58056640625,
          4253.14599609375
         ]
        },
        {
         "fill": "tonexty",
         "fillcolor": "rgba(255, 211, 0, 0.1)",
         "mode": "lines",
         "name": "99 Lower C.I. Bound",
         "type": "scatter",
         "x": [
          "2023-02-02T01:00:00",
          "2023-02-02T02:00:00",
          "2023-02-02T03:00:00",
          "2023-02-02T04:00:00",
          "2023-02-02T05:00:00",
          "2023-02-02T06:00:00",
          "2023-02-02T07:00:00",
          "2023-02-02T08:00:00",
          "2023-02-02T09:00:00",
          "2023-02-02T10:00:00",
          "2023-02-02T11:00:00",
          "2023-02-02T12:00:00",
          "2023-02-02T13:00:00",
          "2023-02-02T14:00:00",
          "2023-02-02T15:00:00",
          "2023-02-02T16:00:00",
          "2023-02-02T17:00:00",
          "2023-02-02T18:00:00",
          "2023-02-02T19:00:00",
          "2023-02-02T20:00:00",
          "2023-02-02T21:00:00",
          "2023-02-02T22:00:00",
          "2023-02-02T23:00:00",
          "2023-02-03T00:00:00",
          "2023-02-03T01:00:00",
          "2023-02-03T02:00:00",
          "2023-02-03T03:00:00",
          "2023-02-03T04:00:00",
          "2023-02-03T05:00:00",
          "2023-02-03T06:00:00",
          "2023-02-03T07:00:00",
          "2023-02-03T08:00:00",
          "2023-02-03T09:00:00",
          "2023-02-03T10:00:00",
          "2023-02-03T11:00:00",
          "2023-02-03T12:00:00",
          "2023-02-03T13:00:00",
          "2023-02-03T14:00:00",
          "2023-02-03T15:00:00",
          "2023-02-03T16:00:00",
          "2023-02-03T17:00:00",
          "2023-02-03T18:00:00",
          "2023-02-03T19:00:00",
          "2023-02-03T20:00:00",
          "2023-02-03T21:00:00",
          "2023-02-03T22:00:00",
          "2023-02-03T23:00:00",
          "2023-02-04T00:00:00",
          "2023-02-04T01:00:00",
          "2023-02-04T02:00:00",
          "2023-02-04T03:00:00",
          "2023-02-04T04:00:00",
          "2023-02-04T05:00:00",
          "2023-02-04T06:00:00",
          "2023-02-04T07:00:00",
          "2023-02-04T08:00:00",
          "2023-02-04T09:00:00",
          "2023-02-04T10:00:00",
          "2023-02-04T11:00:00",
          "2023-02-04T12:00:00",
          "2023-02-04T13:00:00",
          "2023-02-04T14:00:00",
          "2023-02-04T15:00:00",
          "2023-02-04T16:00:00",
          "2023-02-04T17:00:00",
          "2023-02-04T18:00:00",
          "2023-02-04T19:00:00",
          "2023-02-04T20:00:00",
          "2023-02-04T21:00:00",
          "2023-02-04T22:00:00",
          "2023-02-04T23:00:00"
         ],
         "y": [
          2482.2705078125,
          2458.37548828125,
          2481.884033203125,
          2527.64697265625,
          2711.890625,
          3038.820556640625,
          3232.28125,
          3278.38623046875,
          3152.940185546875,
          3120.774169921875,
          3032.9833984375,
          3001.906982421875,
          3000.78271484375,
          2978.254638671875,
          3044.196044921875,
          3157.00732421875,
          3403.95263671875,
          3415.354248046875,
          3286.499267578125,
          3306.57666015625,
          3058.4560546875,
          2853.007080078125,
          2576.55224609375,
          2427.380859375,
          2254.897705078125,
          2264.792724609375,
          2280.863037109375,
          2291.81787109375,
          2402.18798828125,
          2787.994140625,
          3008.56640625,
          3197.184326171875,
          3279.28662109375,
          3296.85400390625,
          3352.2763671875,
          3358.3076171875,
          3342.235595703125,
          3371.623779296875,
          3458.9658203125,
          3671.648681640625,
          3859.435302734375,
          3919.40673828125,
          3873.333740234375,
          3804.64306640625,
          3626.66943359375,
          3390.2685546875,
          3289.0009765625,
          3098.92724609375,
          2992.6064453125,
          2926.254638671875,
          2937.2802734375,
          2973.96484375,
          3042.535888671875,
          3228.300537109375,
          3418.84423828125,
          3598.988037109375,
          3691.43359375,
          3670.668212890625,
          3642.5654296875,
          3589.4375,
          3478.62841796875,
          3485.733154296875,
          3509.63232421875,
          3696.9462890625,
          3835.9091796875,
          3729.34228515625,
          3692.732666015625,
          3575.00830078125,
          3447.81298828125,
          3188.49169921875,
          2996.011474609375
         ]
        },
        {
         "mode": "lines",
         "name": "Real Values",
         "type": "scatter",
         "x": [
          "2023-02-02T01:00:00",
          "2023-02-02T02:00:00",
          "2023-02-02T03:00:00",
          "2023-02-02T04:00:00",
          "2023-02-02T05:00:00",
          "2023-02-02T06:00:00",
          "2023-02-02T07:00:00",
          "2023-02-02T08:00:00",
          "2023-02-02T09:00:00",
          "2023-02-02T10:00:00",
          "2023-02-02T11:00:00",
          "2023-02-02T12:00:00",
          "2023-02-02T13:00:00",
          "2023-02-02T14:00:00",
          "2023-02-02T15:00:00",
          "2023-02-02T16:00:00",
          "2023-02-02T17:00:00",
          "2023-02-02T18:00:00",
          "2023-02-02T19:00:00",
          "2023-02-02T20:00:00",
          "2023-02-02T21:00:00",
          "2023-02-02T22:00:00",
          "2023-02-02T23:00:00",
          "2023-02-03T00:00:00",
          "2023-02-03T01:00:00",
          "2023-02-03T02:00:00",
          "2023-02-03T03:00:00",
          "2023-02-03T04:00:00",
          "2023-02-03T05:00:00",
          "2023-02-03T06:00:00",
          "2023-02-03T07:00:00",
          "2023-02-03T08:00:00",
          "2023-02-03T09:00:00",
          "2023-02-03T10:00:00",
          "2023-02-03T11:00:00",
          "2023-02-03T12:00:00",
          "2023-02-03T13:00:00",
          "2023-02-03T14:00:00",
          "2023-02-03T15:00:00",
          "2023-02-03T16:00:00",
          "2023-02-03T17:00:00",
          "2023-02-03T18:00:00",
          "2023-02-03T19:00:00",
          "2023-02-03T20:00:00",
          "2023-02-03T21:00:00",
          "2023-02-03T22:00:00",
          "2023-02-03T23:00:00",
          "2023-02-04T00:00:00",
          "2023-02-04T01:00:00",
          "2023-02-04T02:00:00",
          "2023-02-04T03:00:00",
          "2023-02-04T04:00:00",
          "2023-02-04T05:00:00",
          "2023-02-04T06:00:00",
          "2023-02-04T07:00:00",
          "2023-02-04T08:00:00",
          "2023-02-04T09:00:00",
          "2023-02-04T10:00:00",
          "2023-02-04T11:00:00",
          "2023-02-04T12:00:00",
          "2023-02-04T13:00:00",
          "2023-02-04T14:00:00",
          "2023-02-04T15:00:00",
          "2023-02-04T16:00:00",
          "2023-02-04T17:00:00",
          "2023-02-04T18:00:00",
          "2023-02-04T19:00:00",
          "2023-02-04T20:00:00",
          "2023-02-04T21:00:00",
          "2023-02-04T22:00:00",
          "2023-02-04T23:00:00"
         ],
         "y": [
          2905.535,
          2891.068,
          2907.027,
          3013.258,
          3209.814,
          3630.465,
          3844.919,
          3774.212,
          3612.646,
          3439.959,
          3262.295,
          3193.152,
          3153.388,
          3196.997,
          3375.496,
          3661.009,
          3957.01,
          4024.739,
          3945.765,
          3817.023,
          3621.628,
          3362.549,
          3128.316,
          2974.505,
          2879.315,
          2831.127,
          2830.837,
          2915.547,
          3138.815,
          3565.716,
          3822.274,
          3803.508,
          3640.567,
          3553.069,
          3514.895,
          3500.915,
          3545.185,
          3642.479,
          3870.487,
          4180.114,
          4473.222,
          4558.433,
          4488.83,
          4437.979,
          4302.486,
          4131.888,
          3899.252,
          3904.398,
          3863.448,
          3808.876,
          3786.456,
          3817.307,
          3921.249,
          4065.164,
          4205.015,
          4253.826,
          4182.738,
          4088.123,
          3984.216,
          3900.039,
          3908.361,
          3927.128,
          4049.955,
          4266.554,
          4404.881,
          4427.551,
          4209.436,
          3986.569,
          3862.851,
          3808.651,
          3616.164
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Uncertainty Quantification for Energy Consumption Test Data"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Energy Demand (MWh)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"73e432d0-64fb-4f5b-ab9f-c34ea9e3c988\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"73e432d0-64fb-4f5b-ab9f-c34ea9e3c988\")) {                    Plotly.newPlot(                        \"73e432d0-64fb-4f5b-ab9f-c34ea9e3c988\",                        [{\"mode\":\"lines\",\"name\":\"99 Upper C.I. Bound\",\"x\":[\"2023-02-02T01:00:00\",\"2023-02-02T02:00:00\",\"2023-02-02T03:00:00\",\"2023-02-02T04:00:00\",\"2023-02-02T05:00:00\",\"2023-02-02T06:00:00\",\"2023-02-02T07:00:00\",\"2023-02-02T08:00:00\",\"2023-02-02T09:00:00\",\"2023-02-02T10:00:00\",\"2023-02-02T11:00:00\",\"2023-02-02T12:00:00\",\"2023-02-02T13:00:00\",\"2023-02-02T14:00:00\",\"2023-02-02T15:00:00\",\"2023-02-02T16:00:00\",\"2023-02-02T17:00:00\",\"2023-02-02T18:00:00\",\"2023-02-02T19:00:00\",\"2023-02-02T20:00:00\",\"2023-02-02T21:00:00\",\"2023-02-02T22:00:00\",\"2023-02-02T23:00:00\",\"2023-02-03T00:00:00\",\"2023-02-03T01:00:00\",\"2023-02-03T02:00:00\",\"2023-02-03T03:00:00\",\"2023-02-03T04:00:00\",\"2023-02-03T05:00:00\",\"2023-02-03T06:00:00\",\"2023-02-03T07:00:00\",\"2023-02-03T08:00:00\",\"2023-02-03T09:00:00\",\"2023-02-03T10:00:00\",\"2023-02-03T11:00:00\",\"2023-02-03T12:00:00\",\"2023-02-03T13:00:00\",\"2023-02-03T14:00:00\",\"2023-02-03T15:00:00\",\"2023-02-03T16:00:00\",\"2023-02-03T17:00:00\",\"2023-02-03T18:00:00\",\"2023-02-03T19:00:00\",\"2023-02-03T20:00:00\",\"2023-02-03T21:00:00\",\"2023-02-03T22:00:00\",\"2023-02-03T23:00:00\",\"2023-02-04T00:00:00\",\"2023-02-04T01:00:00\",\"2023-02-04T02:00:00\",\"2023-02-04T03:00:00\",\"2023-02-04T04:00:00\",\"2023-02-04T05:00:00\",\"2023-02-04T06:00:00\",\"2023-02-04T07:00:00\",\"2023-02-04T08:00:00\",\"2023-02-04T09:00:00\",\"2023-02-04T10:00:00\",\"2023-02-04T11:00:00\",\"2023-02-04T12:00:00\",\"2023-02-04T13:00:00\",\"2023-02-04T14:00:00\",\"2023-02-04T15:00:00\",\"2023-02-04T16:00:00\",\"2023-02-04T17:00:00\",\"2023-02-04T18:00:00\",\"2023-02-04T19:00:00\",\"2023-02-04T20:00:00\",\"2023-02-04T21:00:00\",\"2023-02-04T22:00:00\",\"2023-02-04T23:00:00\"],\"y\":[3469.1669921875,3544.45458984375,3550.496826171875,3608.80810546875,3870.0478515625,4389.7548828125,4636.31787109375,4655.67236328125,4495.1865234375,4444.0986328125,4382.64794921875,4321.0615234375,4232.90966796875,4243.0498046875,4287.53125,4535.4091796875,4831.01611328125,4894.41015625,4815.53662109375,4605.61083984375,4396.015625,4068.855224609375,3714.94287109375,3472.34765625,3242.962158203125,3221.199951171875,3204.552978515625,3269.54248046875,3445.79248046875,3870.50390625,4353.9736328125,4538.21484375,4645.33984375,4729.302734375,4759.0986328125,4768.2802734375,4784.2373046875,4850.9140625,4910.6044921875,5205.29248046875,5466.52685546875,5613.42138671875,5514.78125,5392.36181640625,5199.54150390625,4910.412109375,4543.8095703125,4442.337890625,4240.0859375,4214.02490234375,4230.78173828125,4309.12158203125,4385.2333984375,4569.146484375,4808.16552734375,5123.1962890625,5208.9921875,5261.5439453125,5140.2041015625,5096.0205078125,5025.12841796875,4954.9853515625,5028.76806640625,5283.1630859375,5364.4013671875,5375.31884765625,5335.5634765625,5145.09326171875,4859.93310546875,4463.58056640625,4253.14599609375],\"type\":\"scatter\"},{\"fill\":\"tonexty\",\"fillcolor\":\"rgba(255, 211, 0, 0.1)\",\"mode\":\"lines\",\"name\":\"99 Lower C.I. Bound\",\"x\":[\"2023-02-02T01:00:00\",\"2023-02-02T02:00:00\",\"2023-02-02T03:00:00\",\"2023-02-02T04:00:00\",\"2023-02-02T05:00:00\",\"2023-02-02T06:00:00\",\"2023-02-02T07:00:00\",\"2023-02-02T08:00:00\",\"2023-02-02T09:00:00\",\"2023-02-02T10:00:00\",\"2023-02-02T11:00:00\",\"2023-02-02T12:00:00\",\"2023-02-02T13:00:00\",\"2023-02-02T14:00:00\",\"2023-02-02T15:00:00\",\"2023-02-02T16:00:00\",\"2023-02-02T17:00:00\",\"2023-02-02T18:00:00\",\"2023-02-02T19:00:00\",\"2023-02-02T20:00:00\",\"2023-02-02T21:00:00\",\"2023-02-02T22:00:00\",\"2023-02-02T23:00:00\",\"2023-02-03T00:00:00\",\"2023-02-03T01:00:00\",\"2023-02-03T02:00:00\",\"2023-02-03T03:00:00\",\"2023-02-03T04:00:00\",\"2023-02-03T05:00:00\",\"2023-02-03T06:00:00\",\"2023-02-03T07:00:00\",\"2023-02-03T08:00:00\",\"2023-02-03T09:00:00\",\"2023-02-03T10:00:00\",\"2023-02-03T11:00:00\",\"2023-02-03T12:00:00\",\"2023-02-03T13:00:00\",\"2023-02-03T14:00:00\",\"2023-02-03T15:00:00\",\"2023-02-03T16:00:00\",\"2023-02-03T17:00:00\",\"2023-02-03T18:00:00\",\"2023-02-03T19:00:00\",\"2023-02-03T20:00:00\",\"2023-02-03T21:00:00\",\"2023-02-03T22:00:00\",\"2023-02-03T23:00:00\",\"2023-02-04T00:00:00\",\"2023-02-04T01:00:00\",\"2023-02-04T02:00:00\",\"2023-02-04T03:00:00\",\"2023-02-04T04:00:00\",\"2023-02-04T05:00:00\",\"2023-02-04T06:00:00\",\"2023-02-04T07:00:00\",\"2023-02-04T08:00:00\",\"2023-02-04T09:00:00\",\"2023-02-04T10:00:00\",\"2023-02-04T11:00:00\",\"2023-02-04T12:00:00\",\"2023-02-04T13:00:00\",\"2023-02-04T14:00:00\",\"2023-02-04T15:00:00\",\"2023-02-04T16:00:00\",\"2023-02-04T17:00:00\",\"2023-02-04T18:00:00\",\"2023-02-04T19:00:00\",\"2023-02-04T20:00:00\",\"2023-02-04T21:00:00\",\"2023-02-04T22:00:00\",\"2023-02-04T23:00:00\"],\"y\":[2482.2705078125,2458.37548828125,2481.884033203125,2527.64697265625,2711.890625,3038.820556640625,3232.28125,3278.38623046875,3152.940185546875,3120.774169921875,3032.9833984375,3001.906982421875,3000.78271484375,2978.254638671875,3044.196044921875,3157.00732421875,3403.95263671875,3415.354248046875,3286.499267578125,3306.57666015625,3058.4560546875,2853.007080078125,2576.55224609375,2427.380859375,2254.897705078125,2264.792724609375,2280.863037109375,2291.81787109375,2402.18798828125,2787.994140625,3008.56640625,3197.184326171875,3279.28662109375,3296.85400390625,3352.2763671875,3358.3076171875,3342.235595703125,3371.623779296875,3458.9658203125,3671.648681640625,3859.435302734375,3919.40673828125,3873.333740234375,3804.64306640625,3626.66943359375,3390.2685546875,3289.0009765625,3098.92724609375,2992.6064453125,2926.254638671875,2937.2802734375,2973.96484375,3042.535888671875,3228.300537109375,3418.84423828125,3598.988037109375,3691.43359375,3670.668212890625,3642.5654296875,3589.4375,3478.62841796875,3485.733154296875,3509.63232421875,3696.9462890625,3835.9091796875,3729.34228515625,3692.732666015625,3575.00830078125,3447.81298828125,3188.49169921875,2996.011474609375],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Real Values\",\"x\":[\"2023-02-02T01:00:00\",\"2023-02-02T02:00:00\",\"2023-02-02T03:00:00\",\"2023-02-02T04:00:00\",\"2023-02-02T05:00:00\",\"2023-02-02T06:00:00\",\"2023-02-02T07:00:00\",\"2023-02-02T08:00:00\",\"2023-02-02T09:00:00\",\"2023-02-02T10:00:00\",\"2023-02-02T11:00:00\",\"2023-02-02T12:00:00\",\"2023-02-02T13:00:00\",\"2023-02-02T14:00:00\",\"2023-02-02T15:00:00\",\"2023-02-02T16:00:00\",\"2023-02-02T17:00:00\",\"2023-02-02T18:00:00\",\"2023-02-02T19:00:00\",\"2023-02-02T20:00:00\",\"2023-02-02T21:00:00\",\"2023-02-02T22:00:00\",\"2023-02-02T23:00:00\",\"2023-02-03T00:00:00\",\"2023-02-03T01:00:00\",\"2023-02-03T02:00:00\",\"2023-02-03T03:00:00\",\"2023-02-03T04:00:00\",\"2023-02-03T05:00:00\",\"2023-02-03T06:00:00\",\"2023-02-03T07:00:00\",\"2023-02-03T08:00:00\",\"2023-02-03T09:00:00\",\"2023-02-03T10:00:00\",\"2023-02-03T11:00:00\",\"2023-02-03T12:00:00\",\"2023-02-03T13:00:00\",\"2023-02-03T14:00:00\",\"2023-02-03T15:00:00\",\"2023-02-03T16:00:00\",\"2023-02-03T17:00:00\",\"2023-02-03T18:00:00\",\"2023-02-03T19:00:00\",\"2023-02-03T20:00:00\",\"2023-02-03T21:00:00\",\"2023-02-03T22:00:00\",\"2023-02-03T23:00:00\",\"2023-02-04T00:00:00\",\"2023-02-04T01:00:00\",\"2023-02-04T02:00:00\",\"2023-02-04T03:00:00\",\"2023-02-04T04:00:00\",\"2023-02-04T05:00:00\",\"2023-02-04T06:00:00\",\"2023-02-04T07:00:00\",\"2023-02-04T08:00:00\",\"2023-02-04T09:00:00\",\"2023-02-04T10:00:00\",\"2023-02-04T11:00:00\",\"2023-02-04T12:00:00\",\"2023-02-04T13:00:00\",\"2023-02-04T14:00:00\",\"2023-02-04T15:00:00\",\"2023-02-04T16:00:00\",\"2023-02-04T17:00:00\",\"2023-02-04T18:00:00\",\"2023-02-04T19:00:00\",\"2023-02-04T20:00:00\",\"2023-02-04T21:00:00\",\"2023-02-04T22:00:00\",\"2023-02-04T23:00:00\"],\"y\":[2905.535,2891.068,2907.027,3013.258,3209.814,3630.465,3844.919,3774.212,3612.646,3439.959,3262.295,3193.152,3153.388,3196.997,3375.496,3661.009,3957.01,4024.739,3945.765,3817.023,3621.628,3362.549,3128.316,2974.505,2879.315,2831.127,2830.837,2915.547,3138.815,3565.716,3822.274,3803.508,3640.567,3553.069,3514.895,3500.915,3545.185,3642.479,3870.487,4180.114,4473.222,4558.433,4488.83,4437.979,4302.486,4131.888,3899.252,3904.398,3863.448,3808.876,3786.456,3817.307,3921.249,4065.164,4205.015,4253.826,4182.738,4088.123,3984.216,3900.039,3908.361,3927.128,4049.955,4266.554,4404.881,4427.551,4209.436,3986.569,3862.851,3808.651,3616.164],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Uncertainty Quantification for Energy Consumption Test Data\"},\"xaxis\":{\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Demand (MWh)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('73e432d0-64fb-4f5b-ab9f-c34ea9e3c988');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
    "test_uncertainty_plot_df = test_uncertainty_plot_df.loc[test_uncertainty_plot_df['Date'].between('2023-02-02 01:00:00', '2023-02-04 23:00:00')]\n",
    "truth_uncertainty_plot_df = testing_df.copy(deep=True)\n",
    "truth_uncertainty_plot_df = truth_uncertainty_plot_df.loc[testing_df['Date'].between('2023-02-02 01:00:00', '2023-02-04 23:00:00')]\n",
    "\n",
    "upper_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['Date'],\n",
    "    y=test_uncertainty_plot_df['99.99% upper_bound'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='99 Upper C.I. Bound'\n",
    "    )\n",
    "lower_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['Date'],\n",
    "    y=test_uncertainty_plot_df['99.99% lower_bound'],\n",
    "    mode='lines',\n",
    "    fill='tonexty',\n",
    "    fillcolor='rgba(255, 211, 0, 0.1)',\n",
    "    name='99 Lower C.I. Bound'\n",
    "    )\n",
    "real_trace = go.Scatter(\n",
    "    x=truth_uncertainty_plot_df['Date'],\n",
    "    y=truth_uncertainty_plot_df['Actual Test Output'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='Real Values'\n",
    "    )\n",
    "\n",
    "data = [upper_trace, lower_trace, real_trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(title='Uncertainty Quantification for Energy Consumption Test Data',\n",
    "                   xaxis_title='Time',\n",
    "                   yaxis_title='Energy Demand (MWh)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7THEK4P96J0S"
   },
   "source": [
    "#### Evaluating Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPuR8L6D6PkL"
   },
   "source": [
    "Using multiple experiments above, 99% confidence intervals have been constructed for each the prediction of the target variable (the logarithm of appliance power consumption). While we can visually observe that the model is generally capturing the behavior of the time-series, approximately only 50% of the real data points lie within a 99% confidence interval from the mean prediction value.\n",
    "\n",
    "Despite the relatively low percentage of points within the confidence interval, it must be noted that Bayesian Neural Networks only seek to quantify the epistemic model uncertainty and does not account for aleatoric uncertainty (i.e. noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mV2_6qekxzLn",
    "outputId": "31c0cd39-7eb6-4b7d-9f75-f139678ab76f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of points for testing contained within 99.99% confidence interval: 0.9975978037062457\n"
     ]
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame()\n",
    "\n",
    "# Using 99% confidence bounds\n",
    "\n",
    "bounds_df['lower_bound'] = test_uncertainty_df['99.99% lower_bound']\n",
    "bounds_df['prediction'] = test_uncertainty_df['energy_demand_mean']\n",
    "bounds_df['real_value'] = testing_df[\"Actual Test Output\"]\n",
    "bounds_df['upper_bound'] = test_uncertainty_df['99.99% upper_bound']\n",
    "\n",
    "bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
    "                          (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
    "\n",
    "print(\"Proportion of points for testing contained within 99.99% confidence interval:\",\n",
    "      bounds_df['contained'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8742\n"
     ]
    }
   ],
   "source": [
    "print(len(bounds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_uncertainty_df['95% lower_bound'] = validation_uncertainty_df['energy_demand_mean'] - 1.645*validation_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "validation_uncertainty_df['95% upper_bound'] = validation_uncertainty_df['energy_demand_mean'] + 1.645*validation_uncertainty_df['energy_demand_std'] #99 % confidene interval\n",
    "\n",
    "validation_uncertainty_df['99.99% lower_bound'] = validation_uncertainty_df['energy_demand_mean'] - 3.15*validation_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "validation_uncertainty_df['99.99% upper_bound'] = validation_uncertainty_df['energy_demand_mean'] + 3.15*validation_uncertainty_df['energy_demand_std'] #99 % confidene interval\n",
    "\n",
    "validation_uncertainty_df['99.999% lower_bound'] = validation_uncertainty_df['energy_demand_mean'] - 3*validation_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "validation_uncertainty_df['99.999% upper_bound'] = validation_uncertainty_df['energy_demand_mean'] + 3*validation_uncertainty_df['energy_demand_std'] #99 % confidene interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of points for validation contained within 99% confidence interval: 0.9637184321791795\n"
     ]
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame()\n",
    "\n",
    "# Using 99% confidence bounds\n",
    "bounds_df['lower_bound'] = validation_uncertainty_df['95% lower_bound']\n",
    "bounds_df['prediction'] = validation_uncertainty_df['energy_demand_mean']\n",
    "bounds_df['real_value'] = validation_df['Actual Val Output']\n",
    "bounds_df['upper_bound'] = validation_uncertainty_df['95% upper_bound']\n",
    "\n",
    "bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
    "                          (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
    "\n",
    "print(\"Proportion of points for validation contained within 99% confidence interval:\",\n",
    "      bounds_df['contained'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_uncertainty_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m95\u001b[39m\u001b[38;5;132;01m% lo\u001b[39;00m\u001b[38;5;124mwer_bound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_uncertainty_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mtraining_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_std\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#99 % confidence interval\u001b[39;00m\n\u001b[1;32m      2\u001b[0m training_uncertainty_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m95\u001b[39m\u001b[38;5;132;01m% u\u001b[39;00m\u001b[38;5;124mpper_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mtraining_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_std\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#99 % confidene interval\u001b[39;00m\n\u001b[1;32m      4\u001b[0m training_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m99.99\u001b[39m\u001b[38;5;132;01m% lo\u001b[39;00m\u001b[38;5;124mwer_bound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m training_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mtraining_uncertainty_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_demand_std\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#99 % confidence interval\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_uncertainty_df' is not defined"
     ]
    }
   ],
   "source": [
    "training_uncertainty_df['95% lower_bound'] = training_uncertainty_df['energy_demand_mean'] - 2*training_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "training_uncertainty_df[\"95% upper_bound\"] = training_uncertainty_df['energy_demand_mean'] + 2*training_uncertainty_df['energy_demand_std'] #99 % confidene interval\n",
    "\n",
    "training_uncertainty_df['99.99% lower_bound'] = training_uncertainty_df['energy_demand_mean'] - 3*training_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "training_uncertainty_df[\"99.99% upper_bound\"] = training_uncertainty_df['energy_demand_mean'] + 3*training_uncertainty_df['energy_demand_std'] #99 % confidene interval\n",
    "\n",
    "training_uncertainty_df['99.999% lower_bound'] = training_uncertainty_df['energy_demand_mean'] - 3.3*training_uncertainty_df['energy_demand_std'] #99 % confidence interval\n",
    "training_uncertainty_df[\"99.999% upper_bound\"] = training_uncertainty_df['energy_demand_mean'] + 3.3*training_uncertainty_df['energy_demand_std'] #99 % confidene interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of points for training contained within 95% confidence interval: 0.8000887592721739\n"
     ]
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame()\n",
    "\n",
    "bounds_df['lower_bound'] = training_uncertainty_df['95% lower_bound']\n",
    "bounds_df['prediction'] = training_uncertainty_df['energy_demand_mean']\n",
    "bounds_df['real_value'] = training_df['Actual Train Output']\n",
    "bounds_df['upper_bound'] = training_uncertainty_df['95% upper_bound']\n",
    "\n",
    "bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
    "                            (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
    "\n",
    "print(\"Proportion of points for training contained within 95% confidence interval:\",\n",
    "        bounds_df['contained'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3858.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[\"Actual Train Output\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(type(training_uncertainty_df[\"energy_demand_mean\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'energy_demand_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'energy_demand_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7068/816110027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_uncertainty_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energy_demand_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Actual Train Output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'energy_demand_mean'"
     ]
    }
   ],
   "source": [
    "training_uncertainty_df = training_uncertainty_df.copy()\n",
    "training_uncertainty_df.reset_index(drop = True, inplace = True)\n",
    "Errors = []\n",
    "\n",
    "index = 0 \n",
    "for prediction in training_uncertainty_df[\"energy_demand_mean\"]:\n",
    "    Errors.append(mean_absolute_error([prediction], [np.float32(training_df[\"Actual Train Output\"].iloc[index])]))\n",
    "    index+=1 \n",
    "\n",
    "TrainingErrors = pd.DataFrame({\"Date\": training_uncertainty_df[\"Date\"], \"Errors\": Errors})\n",
    "print(f\"The average training error: {np.mean(Errors)}\")\n",
    "print(f\"The standard deviation of the training error: \", np.std(Errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1: Mean Error: 355.8820883038873, Standard deviation: 179.6376399021649\n",
      "Month 2: Mean Error: 318.6854042994382, Standard deviation: 167.66967256322022\n",
      "Month 3: Mean Error: 263.2997683090509, Standard deviation: 159.55056469329557\n",
      "Month 4: Mean Error: 236.82948802429954, Standard deviation: 160.30002550526015\n",
      "Month 5: Mean Error: 272.32305361293123, Standard deviation: 197.23561134524303\n",
      "Month 6: Mean Error: 341.37885804352936, Standard deviation: 220.9886486996582\n",
      "Month 7: Mean Error: 368.61935165933954, Standard deviation: 214.3272664519809\n",
      "Month 8: Mean Error: 367.21425439978157, Standard deviation: 205.31608433515157\n",
      "Month 9: Mean Error: 302.83850082585843, Standard deviation: 203.18502214129342\n",
      "Month 10: Mean Error: 258.26532354320676, Standard deviation: 188.74895103266627\n",
      "Month 11: Mean Error: 260.4365661997854, Standard deviation: 181.30149935701726\n",
      "Month 12: Mean Error: 326.3108008250093, Standard deviation: 197.1850511364065\n"
     ]
    }
   ],
   "source": [
    "MonthErrors = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[]}\n",
    "\n",
    "for i in range(len(training_uncertainty_df[\"Date\"])):\n",
    "    date = training_uncertainty_df[\"Date\"].iloc[i]\n",
    "    MonthErrors[date.month].append(Errors[i])\n",
    "    \n",
    "for key in MonthErrors.keys():\n",
    "    mean = np.mean(MonthErrors[key])\n",
    "    std = np.std(MonthErrors[key])\n",
    "    MonthErrors[key] = (mean, std)\n",
    "    print(f\"Month {key}: Mean Error: {mean}, Standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assuming MonthErrors is a dictionary where:\n",
    "# - keys are months\n",
    "# - values are lists where the first element is the mean error and the second element is the standard deviation\n",
    "\n",
    "# Extracting months, mean errors, and standard deviations\n",
    "months = list(MonthErrors.keys())\n",
    "mean_errors = [MonthErrors[key][0] for key in months]\n",
    "std_devs = [MonthErrors[key][1] for key in months]\n",
    "error_bars = [(0, std) for std in std_devs]\n",
    "\n",
    "# Creating the bar plot with error bars\n",
    "plt.bar(months, mean_errors, yerr=error_bars, capsize=5)  # capsize specifies the width of the horizontal line at the top of the error bar\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Error in MWH\")\n",
    "plt.title(\"Monthly Error with Standard Deviation for Training\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date' 'Actual Val Output' 'Predicted Val Output']\n"
     ]
    }
   ],
   "source": [
    "print(validation_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average validation error: 142.62649155272322\n",
      "The standard deviation of the validation error:  150.2223354764682\n"
     ]
    }
   ],
   "source": [
    "Errors = []\n",
    "\n",
    "index = 0 \n",
    "for prediction in validation_uncertainty_df[\"energy_demand_mean\"]:\n",
    "    Errors.append(mean_absolute_error([prediction], [np.float32(validation_df[\"Actual Val Output\"].iloc[index])]))\n",
    "    index+=1 \n",
    "\n",
    "TrainingErrors = pd.DataFrame({\"Date\": validation_uncertainty_df[\"Date\"], \"Errors\": Errors})\n",
    "print(f\"The average validation error: {np.mean(Errors)}\")\n",
    "print(f\"The standard deviation of the validation error: \", np.std(Errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1: Mean Error: 118.44756618326599, Standard deviation: 95.80203227893094\n",
      "Month 2: Mean Error: 105.26032195694145, Standard deviation: 81.53689128734719\n",
      "Month 3: Mean Error: 112.77356383621051, Standard deviation: 94.36623917762812\n",
      "Month 4: Mean Error: 164.07736850314672, Standard deviation: 126.95249143522399\n",
      "Month 5: Mean Error: 206.0866430139029, Standard deviation: 139.19298963103097\n",
      "Month 6: Mean Error: 142.2864568074544, Standard deviation: 103.92510814749905\n",
      "Month 7: Mean Error: 164.42635550550236, Standard deviation: 135.23000944623627\n",
      "Month 8: Mean Error: 249.9002227783203, Standard deviation: 343.26564850483646\n",
      "Month 9: Mean Error: 103.16950666639539, Standard deviation: 83.01309334931523\n",
      "Month 10: Mean Error: 85.04166601037467, Standard deviation: 72.33119986246592\n",
      "Month 11: Mean Error: 106.6361339992947, Standard deviation: 105.59245059065316\n",
      "Month 12: Mean Error: 148.7042760425429, Standard deviation: 110.63877117899848\n"
     ]
    }
   ],
   "source": [
    "MonthErrors = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[]}\n",
    "\n",
    "for i in range(len(validation_uncertainty_df[\"Date\"])):\n",
    "    date = validation_uncertainty_df[\"Date\"].iloc[i]\n",
    "    MonthErrors[date.month].append(Errors[i])\n",
    "    \n",
    "for key in MonthErrors.keys():\n",
    "    mean = np.mean(MonthErrors[key])\n",
    "    std = np.std(MonthErrors[key])\n",
    "    MonthErrors[key] = (mean, std)\n",
    "    print(f\"Month {key}: Mean Error: {mean}, Standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming MonthErrors is a dictionary where:\n",
    "# - keys are months\n",
    "# - values are lists where the first element is the mean error and the second element is the standard deviation\n",
    "\n",
    "# Extracting months, mean errors, and standard deviations\n",
    "months = list(MonthErrors.keys())\n",
    "mean_errors = [MonthErrors[key][0] for key in months]\n",
    "std_devs = [MonthErrors[key][1] for key in months]\n",
    "\n",
    "# Specifying that the lower part of the error bar is 0 and the upper part is the standard deviation\n",
    "error_bars = np.array([(0,)*len(std_devs), std_devs])\n",
    "\n",
    "# Creating the bar plot with error bars\n",
    "plt.bar(months, mean_errors, yerr=error_bars, capsize=5)\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Error in MWH\")\n",
    "plt.title(\"Monthly Error with Upper Standard Deviation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average validation error: 134.29482145505173\n",
      "The standard deviation of the validation error:  122.67691049086028\n"
     ]
    }
   ],
   "source": [
    "#test_uncertainty_df.reset_index(inplace = True, drop = True)\n",
    "Errors = []\n",
    "index = 0 \n",
    "for prediction in test_uncertainty_df[\"energy_demand_mean\"]:\n",
    "    Errors.append(mean_absolute_error([prediction], [np.float32(testing_df[\"Actual Test Output\"].iloc[index])]))\n",
    "    index+=1 \n",
    "\n",
    "TrainingErrors = pd.DataFrame({\"Date\": test_uncertainty_df[\"Date\"], \"Errors\": Errors})\n",
    "print(f\"The average validation error: {np.mean(Errors)}\")\n",
    "print(f\"The standard deviation of the validation error: \", np.std(Errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1: Mean Error: 135.18898038498165, Standard deviation: 102.9366677059983\n",
      "Month 2: Mean Error: 139.31101832314144, Standard deviation: 109.8977038227358\n",
      "Month 3: Mean Error: 125.00034706908743, Standard deviation: 125.08219304459482\n",
      "Month 4: Mean Error: 166.8566517582646, Standard deviation: 165.24465736925427\n",
      "Month 5: Mean Error: 161.02209390619748, Standard deviation: 157.4744328516692\n",
      "Month 6: Mean Error: 133.88663838704426, Standard deviation: 108.57089020634635\n",
      "Month 7: Mean Error: 147.70042331927993, Standard deviation: 119.31557958059454\n",
      "Month 8: Mean Error: 145.40481873652413, Standard deviation: 132.88406041731568\n",
      "Month 9: Mean Error: 116.56155401159216, Standard deviation: 105.89919392558156\n",
      "Month 10: Mean Error: 102.02410483958474, Standard deviation: 101.9011362305295\n",
      "Month 11: Mean Error: 113.44039832221137, Standard deviation: 110.84655755615418\n",
      "Month 12: Mean Error: 125.42552737437695, Standard deviation: 91.44336243821074\n"
     ]
    }
   ],
   "source": [
    "MonthErrors = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[]}\n",
    "\n",
    "for i in range(len(test_uncertainty_df[\"Date\"])):\n",
    "    date = test_uncertainty_df[\"Date\"].iloc[i]\n",
    "    MonthErrors[date.month].append(Errors[i])\n",
    "    \n",
    "for key in MonthErrors.keys():\n",
    "    mean = np.mean(MonthErrors[key])\n",
    "    std = np.std(MonthErrors[key])\n",
    "    MonthErrors[key] = (mean, std)\n",
    "    print(f\"Month {key}: Mean Error: {mean}, Standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGOElEQVR4nO3deXxM9/7H8fdkm0QWEWQrQmlrr16K2FVqvVKqVUqF+qEaVbSqaJFuit5WtYr29ke3UHrRVi1XLVG78lNbS6las1xbQkLW8/ujj8w1EmRIzDhez8djHjLf851zPufMZLxzzvecYzEMwxAAAIBJuTm7AAAAgJJE2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2MFtwWKxaMiQIdftN2fOHFksFv35558lX5TJrF27VhaLRWvXri1y32+++abkC0OJcuR9Lw4Wi0UTJky4Jcu6GX/++acsFovmzJlTrPOtXLmy+vbtW6zzxPURdu5w+eHAYrFo/fr1BaYbhqGKFSvKYrHo73//e4nWsnHjRk2YMEHnzp0r0eU4om/fvrbtc+XD29vb2eWVuPj4eE2dOrXY5zthwgRZLBadOnWq0Om1a9dWq1atin25t0peXp4+//xzNWrUSEFBQfL399e9996rPn36aPPmzbZ++/bt04QJEwjnV8gPGvkPT09PlStXTk2aNNGYMWN09OhRZ5d4Ta74XXan83B2AXAN3t7eio+PV7NmzezaExISdPz4cVmt1hKvYePGjYqLi1Pfvn0VGBhY4ssrKqvVqn/+858F2t3d3Z1QTclp0aKFLl68KC8vL1tbfHy89uzZo2HDhjmvsNvQ0KFDNX36dD3yyCPq1auXPDw8tH//fi1btkx33323GjduLOmvsBMXF6dWrVqpcuXKzi3aBfXs2VMdO3ZUXl6ezp49q23btmnq1Kl6//339emnn6pHjx4ltuyIiAhdvHhRnp6eDr/2Wt9l+/fvl5sb+xluNcIOJEkdO3bUggULNG3aNHl4/PdjER8fr/r161/1L/A7gYeHh3r37u3w69LT0+Xr61votIyMDJUqVeqGa8rJyVFeXp5dMLlZbm5ud8TequKQl5enrKysQrdXcnKyPvroIw0YMEAff/yx3bSpU6fqP//5z60q0ymu9bl31N/+9rcCv3tHjhxR27ZtFRMToxo1auj+++8vlmVdqaT23t6KPxxREPESkv76C+r06dNauXKlrS0rK0vffPONnnzyyUJfk56erhdeeEEVK1aU1WrVfffdp3feeUeGYdj1yx9vs3jxYtWuXVtWq1W1atXS8uXLbX0mTJigkSNHSpKqVKli23195e79a82jMDExMSpXrpyys7MLTGvbtq3uu+++a76+qPIPByYkJOjZZ59VcHCwKlSoIElq1aqVateure3bt6tFixYqVaqUxowZI0lKSUlR//79FRISIm9vb91///367LPP7Oadv0v/nXfe0dSpU1W1alVZrVbt27ev0FoeffRR/e1vf7Nr69y5sywWi7777jtb25YtW2SxWLRs2TJJBcdutGrVSj/88IOOHDliez+u3PuQl5enN998UxUqVJC3t7fatGmjgwcP3vB2vJr82r7++muNGTNGoaGh8vX1VXR0tI4dO2bX9/Lt3aRJE/n4+KhKlSqaOXNmgflmZmZq/PjxqlatmqxWqypWrKiXXnpJmZmZdv3yP8NfffWVatWqJavVetXP3uHDh2UYhpo2bVpgmsViUXBwsKS/PjOPP/64JKl169a2bZy//b/99lt16tRJ4eHhslqtqlq1ql5//XXl5uYWur779u1T69atVapUKd11112aPHlygeUfP35cXbp0ka+vr4KDgzV8+PAC6ypJP/30kx5//HFVqlTJtl2GDx+uixcv2vXr27ev/Pz8dOjQIXXs2FH+/v7q1auXbdsOHz5c5cuXl7+/v6Kjo3X8+PFCt5kjIiIiNGfOHGVlZRVYx3PnzmnYsGG276Rq1app0qRJysvLkyRlZ2crKChI/fr1KzDftLQ0eXt768UXX5RU+JidXbt2qW/fvrr77rvl7e2t0NBQPf300zp9+rStz/W+ywobs/PHH3/o8ccfV1BQkEqVKqXGjRvrhx9+sOuT/zswf/78W/I7Zzbs2YGkv34BIyMjNXfuXHXo0EGStGzZMqWmpqpHjx6aNm2aXX/DMBQdHa01a9aof//+qlevnlasWKGRI0fqxIkTeu+99+z6r1+/XgsXLtSzzz4rf39/TZs2Td26ddPRo0dVtmxZPfroozpw4IDmzp2r9957T+XKlZMklS9fvsjzKMxTTz2lzz//XCtWrLAbc5SUlKTVq1dr/PjxRdo+he3Z8vLyUkBAgF3bs88+q/Lly2vcuHFKT0+3tZ8+fVodOnRQjx491Lt3b4WEhOjixYtq1aqVDh48qCFDhqhKlSpasGCB+vbtq3Pnzun555+3m/fs2bN16dIlDRw4UFarVUFBQYXW2rx5c3377bdKS0tTQECADMPQhg0b5Obmpp9++knR0dGS/voPzc3NrdD/lCVp7NixSk1N1fHjx23vp5+fn12ft99+W25ubnrxxReVmpqqyZMnq1evXtqyZct1tuiNefPNN2WxWDRq1CilpKRo6tSpioqK0s6dO+Xj42Prd/bsWXXs2FHdu3dXz549NX/+fA0ePFheXl56+umnJf0V1KKjo7V+/XoNHDhQNWrU0O7du/Xee+/pwIEDWrx4sd2yV69erfnz52vIkCEqV67cVQ87RURESJIWLFigxx9//Kp78Fq0aKGhQ4dq2rRpGjNmjGrUqCFJtn/nzJkjPz8/jRgxQn5+flq9erXGjRuntLQ0TZkyxW5eZ8+eVfv27fXoo4+qe/fu+uabbzRq1CjVqVPH9vt88eJFtWnTRkePHtXQoUMVHh6uL774QqtXry5Q24IFC5SRkaHBgwerbNmy2rp1qz744AMdP35cCxYssOubk5Ojdu3aqVmzZnrnnXds6/s///M/+vLLL/Xkk0+qSZMmWr16tTp16lTotnBUZGSkqlatavfHWUZGhlq2bKkTJ05o0KBBqlSpkjZu3KjRo0crMTFRU6dOlaenp7p27aqFCxdq1qxZdntGFy9erMzMzGseGlu5cqX++OMP9evXT6Ghodq7d68+/vhj7d27V5s3b5bFYinSd9nlkpOT1aRJE2VkZGjo0KEqW7asPvvsM0VHR+ubb75R165d7frf6t850zBwR5s9e7Yhydi2bZvx4YcfGv7+/kZGRoZhGIbx+OOPG61btzYMwzAiIiKMTp062V63ePFiQ5Lxxhtv2M3vscceMywWi3Hw4EFbmyTDy8vLru2XX34xJBkffPCBrW3KlCmGJOPw4cMF6izqPPLXJ38eubm5RoUKFYwnnnjCbn7vvvuuYbFYjD/++OOa2ycmJsaQVOijXbt2BZbbrFkzIycnx24eLVu2NCQZM2fOtGufOnWqIcn48ssvbW1ZWVlGZGSk4efnZ6SlpRmGYRiHDx82JBkBAQFGSkrKNes1DMPYtm2bIclYunSpYRiGsWvXLkOS8fjjjxuNGjWy9YuOjjYeeOAB2/M1a9YYkow1a9bY2jp16mREREQUWEZ+3xo1ahiZmZm29vfff9+QZOzevfuaNY4fP96QZPznP/8pdHqtWrWMli1bFljeXXfdZdsuhmEY8+fPNyQZ77//vq0tf3v/4x//sLVlZmYa9erVM4KDg42srCzDMAzjiy++MNzc3IyffvrJbtkzZ840JBkbNmywtUky3NzcjL17915zvfL16dPHkGSUKVPG6Nq1q/HOO+8Yv/76a4F+CxYsKLDN8+X/Hl5u0KBBRqlSpYxLly4VWN/PP//cbn1DQ0ONbt262dryP2/z58+3taWnpxvVqlUrUENhy544caJhsViMI0eO2Nryfz9efvllu747d+40JBnPPvusXfuTTz5pSDLGjx9fYP6Xy//MT5ky5ap9HnnkEUOSkZqaahiGYbz++uuGr6+vceDAAbt+L7/8suHu7m4cPXrUMAzDWLFihSHJ+P777+36dezY0bj77rsL1DB79mxbW2HbZe7cuYYkY926dba2a32XRUREGDExMbbnw4YNMyTZfQ7Pnz9vVKlSxahcubKRm5trGMbN/87d6TiMBZvu3bvr4sWLWrJkic6fP68lS5Zc9RDW0qVL5e7urqFDh9q1v/DCCzIMw3ZoJF9UVJSqVq1qe163bl0FBATojz/+KHJ9NzIPNzc39erVS999953Onz9va//qq6/UpEkTValS5brL9fb21sqVKws83n777QJ9BwwYUOjAZavVWmDX+dKlSxUaGqqePXva2jw9PTV06FBduHBBCQkJdv27det21b8OL/fAAw/Iz89P69atk/TXHpwKFSqoT58+2rFjhzIyMmQYhtavX6/mzZtfd37X0q9fP7u/jvPn58j76og+ffrI39/f9vyxxx5TWFiYli5datfPw8NDgwYNsj338vLSoEGDlJKSou3bt0v6a+9FjRo1VL16dZ06dcr2eOihhyRJa9assZtny5YtVbNmzSLVOXv2bH344YeqUqWKFi1apBdffFE1atRQmzZtdOLEiSLN4/I9VefPn9epU6fUvHlzZWRk6LfffrPr6+fnZze2xcvLSw0bNrR7H5YuXaqwsDA99thjtrZSpUpp4MCB11x2enq6Tp06pSZNmsgwDP3f//1fgf6DBw+2e57/flz5/VCcA93z9zLm/14vWLBAzZs3V5kyZezez6ioKOXm5tp+Hx566CGVK1dOX3/9tW1eZ8+e1cqVK/XEE09cc5mXb5dLly7p1KlTtsHmO3bsuKH1WLp0qRo2bGh3coifn58GDhyoP//8s8Dh6lv9O2cWHMaCTfny5RUVFaX4+HhlZGQoNzfX7ovxckeOHFF4eLjdfzzSf3fBHzlyxK69UqVKBeZRpkwZnT17tsj13eg8+vTpo0mTJmnRokXq06eP9u/fr+3btxc6hqMw7u7uioqKKlLfq4Wnu+66q8Bg4iNHjuiee+4pcGbG1bZhUYJZfr2RkZH66aefJP0Vdpo3b65mzZopNzdXmzdvVkhIiM6cOXPTYefK96RMmTKS5ND7ejUWi6VA2z333FOgT7Vq1QqM7QoPDy8wSPbee++V9NdYjMaNG+v333/Xr7/+etUAmZKSYve8qNtf+itkx8bGKjY2VqdPn9aGDRs0c+ZMLVu2TD169LC9N9eyd+9evfLKK1q9erXS0tLspqWmpto9r1ChQoHtVaZMGe3atcv2/MiRI6pWrVqBfoWNWzt69KjGjRun7777rsB7eeWyPTw8bOPTLl+Wm5ub3R8nV1vWjbpw4YIk2b6Dfv/9d+3ateu676eHh4e6deum+Ph4ZWZmymq1auHChcrOzr5u2Dlz5ozi4uI0b968Ap+PK7dLUR05ckSNGjUq0H7590Dt2rVt7SX5O2dmhB3YefLJJzVgwAAlJSWpQ4cOxXYK+NVO0zauGMxcEvOoWbOm6tevry+//FJ9+vTRl19+KS8vL3Xv3r3Iyy6qy//yK0p7ccy7MM2aNdObb76pS5cu6aefftLYsWMVGBio2rVr66efflJISIgk3XTYudH3JP8slysHvObLyMgo8TPD8vLyVKdOHb377ruFTq9YsaLd8xt9D8uWLavo6GhFR0erVatWSkhI0JEjR2xjewpz7tw5tWzZUgEBAXrttddUtWpVeXt7a8eOHRo1apRtwG2+4vj9ypebm6uHH35YZ86c0ahRo1S9enX5+vrqxIkT6tu3b4FlW61Wp5xKvWfPHgUHB9vGzeXl5enhhx/WSy+9VGj//LArST169NCsWbO0bNkydenSRfPnz1f16tWve2ZX9+7dtXHjRo0cOVL16tWTn5+f8vLy1L59+wLbpaQU53t9JyHswE7Xrl01aNAgbd682W4375UiIiL0448/6vz583Z7d/J3r1/ri/xqCvtLvrj06dNHI0aMUGJiouLj49WpUyfbX0TOEhERoV27dikvL8/uP4ub2Yb5mjdvrqysLM2dO1cnTpywhZoWLVrYws69995rCz1XU1LvSf667d+/v0CoyMjI0LFjx9S2bdsCr/v999/tnhuGoYMHD6pu3bp27SdPnixwCvSBAwckyTawuGrVqvrll1/Upk2bEv3sXa5BgwZKSEhQYmKiIiIirrrctWvX6vTp01q4cKFatGhhaz98+PANLzsiIkJ79uyRYRh2y92/f79dv927d+vAgQP67LPP1KdPH1v75YOBi7KsvLw8HTp0yG5vzpXLulGbNm3SoUOH7A7dVa1aVRcuXCjSXtgWLVooLCxMX3/9tZo1a6bVq1dr7Nix13zN2bNntWrVKsXFxWncuHG29is/k5JjvzcRERGFbpfi+B7AfzFmB3b8/Pw0Y8YMTZgwQZ07d75qv44dOyo3N1cffvihXft7770ni8ViOwPEEfn/MZXEVUd79uwpi8Wi559/Xn/88ccNXTenuHXs2FFJSUl2oTInJ0cffPCB/Pz81LJlyxued6NGjeTp6alJkyYpKChItWrVkvRXCNq8ebMSEhKKtFfH19f3hnfPX0ubNm3k5eWlGTNmFPiL+OOPP1ZOTk6hn6HPP//cbuzVN998o8TExAJ9c3JyNGvWLNvzrKwszZo1S+XLl1f9+vUl/fVX+okTJ/TJJ58UWM7FixftzqZzRFJSUqGXBcjKytKqVavk5uamatWqSbr6Zz7/r/fL/1rPysrSRx99dEM1SX993k6ePGl3i4+MjIwC1wIqbNmGYej9998v8rLy348rz+IsjqtxHzlyRH379pWXl5ftFG/pr/dz06ZNWrFiRYHXnDt3Tjk5Obbnbm5ueuyxx/T999/riy++UE5OznUPYRW2XaTC18mR77KOHTtq69at2rRpk60tPT1dH3/8sSpXrlzkcWK4NvbsoICYmJjr9uncubNat26tsWPH6s8//9T999+vf//73/r22281bNiwAsfqiyL/P6GxY8eqR48e8vT0VOfOnYvlAmXly5dX+/bttWDBAgUGBjp0CmxOTo6+/PLLQqd17dr1husbOHCgZs2apb59+2r79u2qXLmyvvnmG23YsEFTp04tMB7KEaVKlVL9+vW1efNm2zV2pL/+ok1PT1d6enqRwk79+vX19ddfa8SIEXrwwQfl5+d3zRBcVMHBwRo3bpxeeeUVtWjRQtHR0SpVqpQ2btyouXPnqm3btoUuJygoSM2aNVO/fv2UnJysqVOnqlq1ahowYIBdv/DwcE2aNEl//vmn7r33Xn399dfauXOnPv74Y9sVcZ966inNnz9fzzzzjNasWaOmTZsqNzdXv/32m+bPn68VK1aoQYMGDq/b8ePH1bBhQz300ENq06aNQkNDlZKSorlz5+qXX37RsGHDbKcj16tXT+7u7po0aZJSU1NltVr10EMPqUmTJipTpoxiYmI0dOhQWSwWffHFFzd1qGLAgAH68MMP1adPH23fvl1hYWH64osvCpwaX716dVWtWlUvvviiTpw4oYCAAP3rX/9yaExIvXr11LNnT3300UdKTU1VkyZNtGrVKoevB7Njxw59+eWXysvL07lz57Rt2zb961//sm2Py/fojRw5Ut99953+/ve/q2/fvqpfv77S09O1e/duffPNN/rzzz9t212SnnjiCX3wwQcaP3686tSpYxsjczUBAQFq0aKFJk+erOzsbN11113697//XejeNke+y15++WXbJT+GDh2qoKAgffbZZzp8+LD+9a9/cbXl4uKEM8DgQi4/9fxarjz13DD+Oj1y+PDhRnh4uOHp6Wncc889xpQpU4y8vDy7fpKM2NjYQud5+SmYhvHX6aN33XWX4ebmZnfqZlHnceWp55fLP0154MCB11zXy13r1PPLl3Ot7diyZUujVq1ahc4/OTnZ6Nevn1GuXDnDy8vLqFOnjt2proZRtNNwCzNy5EhDkjFp0iS79vxTjQ8dOmTXXtip5xcuXDCefPJJIzAw0JBkOw09v++CBQsKrfXKdbiaL7/80mjcuLHh6+trWK1Wo3r16kZcXJzdqdWXL2/u3LnG6NGjjeDgYMPHx8fo1KmT3anQhvHf7f3zzz8bkZGRhre3txEREWF8+OGHBZaflZVlTJo0yahVq5ZhtVqNMmXKGPXr1zfi4uJspzQbxtU/f4VJS0sz3n//faNdu3ZGhQoVDE9PT8Pf39+IjIw0PvnkkwK/H5988olx9913G+7u7nbbf8OGDUbjxo0NHx8fIzw83HjppZdsp01f/h5d7fMVExNT4LIBR44cMaKjo41SpUoZ5cqVM55//nlj+fLlBea5b98+IyoqyvDz8zPKlStnDBgwwHaph8vf25iYGMPX17fQ7XDx4kVj6NChRtmyZQ1fX1+jc+fOxrFjxxw69Tz/4eHhYQQFBRmNGjUyRo8eXeA9z3f+/Hlj9OjRRrVq1QwvLy+jXLlyRpMmTYx33nnHdsmBfHl5eUbFihULvYTG5TVcvr7Hjx83unbtagQGBhqlS5c2Hn/8cePkyZOFrtPVvssK+947dOiQ8dhjjxmBgYGGt7e30bBhQ2PJkiV2fYrrd+5OZTEMRjXhzvDtt9+qS5cuWrdu3U0PzMWttXbtWrVu3VoLFiy46hmC+Vq1aqVTp05pz549t6g6AK6O/WO4Y3zyySe6++67C9zsFABgbozZgenNmzdPu3bt0g8//KD333//lp15AwBwDYQdmF7Pnj3l5+en/v3769lnn3V2OQCAW4wxOwAAwNQYswMAAEyNsAMAAEyNMTv6654qJ0+elL+/P4NXAQC4TRiGofPnzys8PPyaF2Ak7Oiv++hceX8eAABwezh27JgqVKhw1emEHcl2Wf5jx47Z7qALAABcW1pamipWrHjd2+sQdvTfO9QGBAQQdgAAuM1cbwgKA5QBAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpeTi7AMAsEhMTlZiY6PDrwsLCFBYWVgIVAQAkwg5QbGbNmqW4uDiHXzd+/HhNmDCh+AsCAEgi7ADFZtCgQYqOjrZru3jxopo1ayZJWr9+vXx8fAq8jr06AFCyCDtAMSnscFR6errt53r16snX1/dWlwUAdzwGKAMAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFPjdhGAyXE3dgB3OsIOYHLcjR3AnY6wA5gcd2MHcKcj7AAmx93YAdzpGKAMAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMzalhZ8aMGapbt64CAgIUEBCgyMhILVu2zDb90qVLio2NVdmyZeXn56du3bopOTnZbh5Hjx5Vp06dVKpUKQUHB2vkyJHKycm51asCAABclFPDToUKFfT2229r+/bt+vnnn/XQQw/pkUce0d69eyVJw4cP1/fff68FCxYoISFBJ0+e1KOPPmp7fW5urjp16qSsrCxt3LhRn332mebMmaNx48Y5a5UAAICLsRiGYTi7iMsFBQVpypQpeuyxx1S+fHnFx8frsccekyT99ttvqlGjhjZt2qTGjRtr2bJl+vvf/66TJ08qJCREkjRz5kyNGjVK//nPf+Tl5VWkZaalpal06dJKTU1VQEBAia0b7jzp6eny8/OTJF24cEG+vr5OrugvrloXADiiqP9/u8yYndzcXM2bN0/p6emKjIzU9u3blZ2draioKFuf6tWrq1KlStq0aZMkadOmTapTp44t6EhSu3btlJaWZts7BAAA7mwezi5g9+7dioyM1KVLl+Tn56dFixapZs2a2rlzp7y8vBQYGGjXPyQkRElJSZKkpKQku6CTPz1/2tVkZmYqMzPT9jwtLa2Y1gYAALgap+/Zue+++7Rz505t2bJFgwcPVkxMjPbt21eiy5w4caJKly5te1SsWLFElwcAAJzH6WHHy8tL1apVU/369TVx4kTdf//9ev/99xUaGqqsrCydO3fOrn9ycrJCQ0MlSaGhoQXOzsp/nt+nMKNHj1ZqaqrtcezYseJdKQAA4DKcHnaulJeXp8zMTNWvX1+enp5atWqVbdr+/ft19OhRRUZGSpIiIyO1e/dupaSk2PqsXLlSAQEBqlmz5lWXYbVabae75z8AAIA5OXXMzujRo9WhQwdVqlRJ58+fV3x8vNauXasVK1aodOnS6t+/v0aMGKGgoCAFBAToueeeU2RkpBo3bixJatu2rWrWrKmnnnpKkydPVlJSkl555RXFxsbKarU6c9UAAICLcGrYSUlJUZ8+fZSYmKjSpUurbt26WrFihR5++GFJ0nvvvSc3Nzd169ZNmZmZateunT766CPb693d3bVkyRINHjxYkZGR8vX1VUxMjF577TVnrRIAAHAxLnedHWfgOjsoKa56PRtXrQsAHHHbXWcHAACgJBB2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqXk4uwAAQNEkJiYqMTHR4deFhYUpLCysBCoCbg+EHQC4TcyaNUtxcXEOv278+PGaMGFC8RcE3CYIOwBwmxg0aJCio6Pt2i5evKhmzZpJktavXy8fH58Cr2OvDu50hB0AuE0UdjgqPT3d9nO9evXk6+t7q8sCXB4DlAEAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKlxUUEAuAL3oALMhbADAFfgHlSAuRB2AOAK3IMKMBfCDgBcgXtQAebCAGUAAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqTg07EydO1IMPPih/f38FBwerS5cu2r9/v12fVq1ayWKx2D2eeeYZuz5Hjx5Vp06dVKpUKQUHB2vkyJHKycm5lasCAABclFPvjZWQkKDY2Fg9+OCDysnJ0ZgxY9S2bVvt27fP7r4zAwYM0GuvvWZ7XqpUKdvPubm56tSpk0JDQ7Vx40YlJiaqT58+8vT01FtvvXVL1wcAALgep4ad5cuX2z2fM2eOgoODtX37drVo0cLWXqpUKYWGhhY6j3//+9/at2+ffvzxR4WEhKhevXp6/fXXNWrUKE2YMEFeXl4lug4AAMC1udSYndTUVElSUFCQXftXX32lcuXKqXbt2ho9erQyMjJs0zZt2qQ6deooJCTE1tauXTulpaVp7969t6ZwAADgspy6Z+dyeXl5GjZsmJo2baratWvb2p988klFREQoPDxcu3bt0qhRo7R//34tXLhQkpSUlGQXdCTZniclJRW6rMzMTGVmZtqep6WlFffqoAQlJiYqMTHR4deFhYUpLCysBCoCALgylwk7sbGx2rNnj9avX2/XPnDgQNvPderUUVhYmNq0aaNDhw6patWqN7SsiRMnKi4u7qbqvRO4aqiYNWvWDb1/48eP14QJE4q/IACAS3OJsDNkyBAtWbJE69atU4UKFa7Zt1GjRpKkgwcPqmrVqgoNDdXWrVvt+iQnJ0vSVcf5jB49WiNGjLA9T0tLU8WKFW9mFUzJVUPFoEGDFB0dbdd28eJFNWvWTJK0fv16+fj4FHgde3UA4M7k1LBjGIaee+45LVq0SGvXrlWVKlWu+5qdO3dK+u9/XJGRkXrzzTeVkpKi4OBgSdLKlSsVEBCgmjVrFjoPq9Uqq9VaPCthYq4aKgrbc5Senm77uV69enZn8wEA7mxODTuxsbGKj4/Xt99+K39/f9sYm9KlS8vHx0eHDh1SfHy8OnbsqLJly2rXrl0aPny4WrRoobp160qS2rZtq5o1a+qpp57S5MmTlZSUpFdeeUWxsbEEmptEqAAAmIFTz8aaMWOGUlNT1apVK9t/rGFhYfr6668lSV5eXvrxxx/Vtm1bVa9eXS+88IK6deum77//3jYPd3d3LVmyRO7u7oqMjFTv3r3Vp08fu+vyAACAO5fTD2NdS8WKFZWQkHDd+URERGjp0qXFVRYAADARl7rODgAAQHFzibOxANyZXPXyBgDMhbADwGlc9fIGAMyFsAPAaVz18gYAzIWwA8BpuLwBgFuBsONkjFkAAKBkEXacjDELAACULMKOkzFmAQCAkkXYcTLGLAAAULK4qCAAADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA17o0FAMAtlpiYqMTERIdfV9j9FHF9hB0AAG6xWbNmKS4uzuHXjR8/XhMmTCj+gkyOsAMAuCnspXDcoEGDFB0dbdd28eJFNWvWTJK0fv16+fj4FHjdnbq9bhZhBwBwU9hL4bjCgl56errt53r16snX1/dWl2VahB0AwE1hLwVcHWEHAHBT2EsBV8ep5wAAwNQIOwAAwNQ4jAUAACSZ98w6wg4AAJBk3jPrihx2du3aVaR+devWveFiAACA85j1zLoih5169erJYrHIMAxJksVikSQZhmFrt1gsys3NLZlKAQBAiTLrmXVFDjuHDx+2/WwYhmrXrq2lS5cqIiKiRAoDAAAoDkUOO1eGGovFogoVKhB2AACAS+PUcwAAYGqEHQAAYGo3FXbyBykDAAC4qiKP2XnggQfsws3FixfVuXNneXl52fXbsWNH8VUHAABwk4ocdh555BG7sPPII4+USEEAAADFqchhx5WvjAgAAHA1RR6zM378eK1bt05ZWVklWQ8AAECxKnLY+eyzz9SqVSsFBgaqTZs2euONN7Rhwwbl5OSUZH0AAAA3pciHsf7880/9+eefWrNmjdauXat//vOfGjdunHx9fdW0aVO1bt1arVu3VsOGDYu88IkTJ2rhwoX67bff5OPjoyZNmmjSpEm67777bH0uXbqkF154QfPmzVNmZqbatWunjz76SCEhIbY+R48e1eDBg7VmzRr5+fkpJiZGEydOlIcH9zkFgDuVWe/gDcc5lAYqV66sfv36qV+/fpL+uoVEfvh56623NHbsWIf29CQkJCg2NlYPPvigcnJyNGbMGLVt21b79u2z3Xtj+PDh+uGHH7RgwQKVLl1aQ4YM0aOPPqoNGzZIknJzc9WpUyeFhoZq48aNSkxMVJ8+feTp6am33nrLkdUDAJiIWe/gDcfd8K6PI0eOaN26dUpISNC6deuUnZ2tFi1aODSP5cuX2z2fM2eOgoODtX37drVo0UKpqan69NNPFR8fr4ceekiSNHv2bNWoUUObN29W48aN9e9//1v79u3Tjz/+qJCQENWrV0+vv/66Ro0apQkTJhQ4NR4AcGcw6x284bgih52jR49q7dq1tj05p06dUpMmTdSyZUsNGDBADRs2vOlgkZqaKkkKCgqSJG3fvl3Z2dmKioqy9alevboqVaqkTZs2qXHjxtq0aZPq1Kljd1irXbt2Gjx4sPbu3asHHnjgpmoCANyezHoHbziuyGGncuXKqlSpkgYPHqzBgwerfv36cnd3L7ZC8vLyNGzYMDVt2lS1a9eWJCUlJcnLy0uBgYF2fUNCQpSUlGTrc3nQyZ+eP60wmZmZyszMtD1PS0srrtUAAAAupshnY3Xv3l2ZmZmaNGmS3njjDU2dOlU7duyQYRjFUkhsbKz27NmjefPmFcv8rmXixIkqXbq07VGxYsUSXyYAAHCOIoedefPmKTExURs3blSHDh20detWdezYUWXKlNHf//53TZkyRdu2bbuhIoYMGaIlS5ZozZo1qlChgq09NDRUWVlZOnfunF3/5ORkhYaG2vokJycXmJ4/rTCjR49Wamqq7XHs2LEbqhsAALg+h28EWr16dQ0ePFhff/21kpKStHHjRtWrV09vvPGGIiMjHZqXYRgaMmSIFi1apNWrV6tKlSp20+vXry9PT0+tWrXK1rZ//34dPXrUtqzIyEjt3r1bKSkptj4rV65UQECAatasWehyrVarAgIC7B4AAMCcbuhsrOTkZK1du9Y2YPnAgQOyWq1q3ry5Q/OJjY1VfHy8vv32W/n7+9vG2JQuXVo+Pj4qXbq0+vfvrxEjRigoKEgBAQF67rnnFBkZqcaNG0uS2rZtq5o1a+qpp57S5MmTlZSUpFdeeUWxsbGyWq03snoAAMBEihx25s+fbws4+/fvl6enpx588EF1795drVu3VpMmTRwOFzNmzJAktWrVyq599uzZ6tu3ryTpvffek5ubm7p162Z3UcF87u7uWrJkiQYPHqzIyEj5+voqJiZGr732mkO1AAAAcypy2Ondu7caNGigrl27qnXr1mratGmh1ydwRFEGN3t7e2v69OmaPn36VftERERo6dKlN1ULAAAwpyKHnbNnz3I9AgAAcNsp8gBlgg4AALgdFXnPTlEvIJibm3vDxQAAABS3IocdwzAUERGhmJgYbsEAAABuG0UOO1u3btWnn36q999/X1WqVNHTTz+tXr16qUyZMiVZHwAAwE0p8pidBg0aaMaMGUpMTNSIESO0aNEiVahQQT169NDKlStLskYAAIAb5vAVlL29vdW7d2+tWrVKe/bsUUpKitq3b68zZ86URH0AAAA35YauoHz8+HHNmTNHc+bMUUZGhkaOHMktFwAAgEsqctjJysrSokWL9Omnn+qnn35Shw4dNHXqVHXo0KHIZ2oBAADcakUOO2FhYfL391dMTIw++ugjBQcHS5LS09Pt+rGHBwAAuBKHrqB89uxZvf7663rjjTcKTDcMQxaLhevsAAAAl1LksLNmzZqSrAMAAKBEFDnstGzZsiTrAAAAKBEOn3oOAABwOyHsAAAAUyPsAAAAUyPsAAAAUyPsAAAAU3P4dhHp6el6++23tWrVKqWkpCgvL89u+h9//FFsxQEAANwsh8PO//zP/yghIUFPPfWUwsLCZLFYSqIuAACAYuFw2Fm2bJl++OEHNW3atCTqAQAAKFYOj9kpU6aMgoKCSqIWAACAYudw2Hn99dc1btw4ZWRklEQ9AAAAxcrhw1j/+Mc/dOjQIYWEhKhy5cry9PS0m75jx45iKw4AAOBmORx2unTpUgJlAAAAlAyHw8748eNLog4AAIASwUUFAQCAqRVpz05QUJAOHDigcuXKqUyZMte8ts6ZM2eKrTgAAICbVaSw895778nf31+SNHXq1JKsB7htJSYmKjEx0a7t4sWLtp937twpHx+fAq8LCwtTWFhYidcHAHeqIoWdmJiYQn8G7iSVX/7hmtPPrf9KqRvmXnV6s2bNCm0v3bSnApv1uurr/ny7U9EKBAAUyuEBygAK51evg3yqNXL4de5+XKQTAEoSYQcoJh5+QfIguACAy+FsLAAAYGqEHQAAYGoOHcbKzs6Wj4+Pdu7cqdq1a5dUTQCKEWeJAbjTORR2PD09ValSJeXm5pZUPQAc5KyzxCTOFANwe3B4gPLYsWM1ZswYffHFFwoKYjAm4Oo4SwzAnc7hsPPhhx/q4MGDCg8PV0REhHx9fe2mc9dzwLVwlhiAOx13PQcAAKbGXc8BAICp3fBFBbdv365ff/1VklSrVi098MADxVYUAABAcXE47KSkpKhHjx5au3atAgMDJUnnzp1T69atNW/ePJUvX764awQAALhhDl9U8LnnntP58+e1d+9enTlzRmfOnNGePXuUlpamoUOHOjSvdevWqXPnzgoPD5fFYtHixYvtpvft21cWi8Xu0b59e7s+Z86cUa9evRQQEKDAwED1799fFy5ccHS1AACASTkcdpYvX66PPvpINWrUsLXVrFlT06dP17JlyxyaV3p6uu6//35Nnz79qn3at29vuyhaYmKi5s61v15Ir169tHfvXq1cuVJLlizRunXrNHDgQMdWCgAAmJbDh7Hy8vLk6elZoN3T01N5eXkOzatDhw7q0KHDNftYrVaFhoYWOu3XX3/V8uXLtW3bNjVo0ECS9MEHH6hjx4565513FB4e7lA9AADAfBzes/PQQw/p+eef18mTJ21tJ06c0PDhw9WmTZtiLU6S1q5dq+DgYN13330aPHiwTp8+bZu2adMmBQYG2oKOJEVFRcnNzU1btmwp9loAAMDt54YuKhgdHa3KlSurYsWKkqRjx46pdu3a+vLLL4u1uPbt2+vRRx9VlSpVdOjQIY0ZM0YdOnTQpk2b5O7urqSkJAUHB9u9xsPDQ0FBQUpKSrrqfDMzM5WZmWl7npaWVqx1AwAA1+Fw2KlYsaJ27NihH3/8Ub/99pskqUaNGoqKiir24nr06GH7uU6dOqpbt66qVq2qtWvX3tRepIkTJyouLq44SgQAAC7uhu96/vDDD+vhhx8uqboKdffdd6tcuXI6ePCg2rRpo9DQUKWkpNj1ycnJ0ZkzZ646zkeSRo8erREjRtiep6Wl2fZSAQB3igfM5ba66/nx48d1+vRp25dJZGSkzp07p+3bt6t+/fqSpNWrVysvL0+NGl39xodWq1VWq/WW1AzAtVzvLvFSyd0pnrvEA87h1LueX7hwQQcPHrQ9P3z4sHbu3KmgoCAFBQUpLi5O3bp1U2hoqA4dOqSXXnpJ1apVU7t27ST9dfisffv2GjBggGbOnKns7GwNGTJEPXr04EwsADeMO8UD5uLUu57//PPPat26te15/qGlmJgYzZgxQ7t27dJnn32mc+fOKTw8XG3bttXrr79ut1fmq6++0pAhQ9SmTRu5ubmpW7dumjZtmqOrBQA2rnqneA6vATfGqXc9b9WqlQzDuOr0FStWXHceQUFBio+PL7aaAMBZrneIjcNrwI1xKOzk5OTIYrHo6aefVoUKFUqqJgBAITi8BtwYh8KOh4eHpkyZoj59+pRUPQCAq3DVw2uAq7uhKygnJCSURC0AAADFzuExOx06dNDLL7+s3bt3q379+gUGKEdHRxdbcQAAADfL4bDz7LPPSpLefffdAtMsFovTrsGD4seZHwAAM7ihu57j9seF1QAAdwqHww7uHJz5AQAwgyKHnY4dO2ru3LkqXbq0JOntt9/WM888o8DAQEnS6dOn1bx5c+3bt69ECsWtx5kfAAAzKHLYWbFihTIzM23P33rrLXXv3t0WdnJycrR///5iL9DsGBcDAEDJKnLYufJKx9e68jH+y1lXRJUYGwMAgMSYHadjXAzuZOzZBHArFDnsWCwWWSyWAm24OYyLgVlxxh8AV+HQYay+ffva7jh+6dIlPfPMM7aLCl4+ngcAioI9mwBuhSKHnZiYGLvnvXv3LtCHe2YBcAR7NgHcCkUOO7Nnzy7JOgAAAEqEwzcCBQAAuJ0QdgAAgKkRdgAAgKkRdgAAgKlxUUHcdrgQHQCUDLN+vxJ24HKcdYsNLkQHwOzu1O9Xwg5uO1yIDgBKhlm/Xwk7uO1wIToAKBlm/X5lgDIAADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1zsYCANwUs16IDuZB2AEAXNOdeiE6mAdhBwBwU8x6ITqYB2EHAHBTzHohupLEob9bi7ADAEAxut5hP4lDf7caYQcAgFuMQ3+3FmEHAIBbjEN/txbX2QEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKbm1LCzbt06de7cWeHh4bJYLFq8eLHddMMwNG7cOIWFhcnHx0dRUVH6/fff7fqcOXNGvXr1UkBAgAIDA9W/f39duHDhFq4FAABwZU4NO+np6br//vs1ffr0QqdPnjxZ06ZN08yZM7Vlyxb5+vqqXbt2unTpkq1Pr169tHfvXq1cuVJLlizRunXrNHDgwFu1CgAAwMU59QrKHTp0UIcOHQqdZhiGpk6dqldeeUWPPPKIJOnzzz9XSEiIFi9erB49eujXX3/V8uXLtW3bNjVo0ECS9MEHH6hjx4565513FB4efsvWBQDgWrjZJvK57O0iDh8+rKSkJEVFRdnaSpcurUaNGmnTpk3q0aOHNm3apMDAQFvQkaSoqCi5ublpy5Yt6tq1qzNKBwDcAte74WZJ3WxT4oabtxuXDTtJSUmSpJCQELv2kJAQ27SkpCQFBwfbTffw8FBQUJCtT2EyMzOVmZlpe56WllZcZQMAXAQ320Q+lw07JWnixImKi4tzdhkAgBLEzTaRz2VPPQ8NDZUkJScn27UnJyfbpoWGhiolJcVuek5Ojs6cOWPrU5jRo0crNTXV9jh27FgxVw8AAFyFy4adKlWqKDQ0VKtWrbK1paWlacuWLYqMjJQkRUZG6ty5c9q+fbutz+rVq5WXl6dGja6+69JqtSogIMDuAQAAzMmph7EuXLiggwcP2p4fPnxYO3fuVFBQkCpVqqRhw4bpjTfe0D333KMqVaro1VdfVXh4uLp06SJJqlGjhtq3b68BAwZo5syZys7O1pAhQ9SjRw/OxAIAAJKcHHZ+/vlntW7d2vZ8xIgRkqSYmBjNmTNHL730ktLT0zVw4ECdO3dOzZo10/Lly+Xt7W17zVdffaUhQ4aoTZs2cnNzU7du3TRt2rRbvi4AAMA1OTXstGrVSoZhXHW6xWLRa6+9ptdee+2qfYKCghQfH18S5QEAABNw2TE7AAAAxYGwAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATM2lw86ECRNksVjsHtWrV7dNv3TpkmJjY1W2bFn5+fmpW7duSk5OdmLFAADA1bh02JGkWrVqKTEx0fZYv369bdrw4cP1/fffa8GCBUpISNDJkyf16KOPOrFaAADgajycXcD1eHh4KDQ0tEB7amqqPv30U8XHx+uhhx6SJM2ePVs1atTQ5s2b1bhx41tdKgAAcEEuv2fn999/V3h4uO6++2716tVLR48elSRt375d2dnZioqKsvWtXr26KlWqpE2bNjmrXAAA4GJces9Oo0aNNGfOHN13331KTExUXFycmjdvrj179igpKUleXl4KDAy0e01ISIiSkpKuOd/MzExlZmbanqelpZVE+QAAwAW4dNjp0KGD7ee6deuqUaNGioiI0Pz58+Xj43PD8504caLi4uKKo0QAAODiXP4w1uUCAwN177336uDBgwoNDVVWVpbOnTtn1yc5ObnQMT6XGz16tFJTU22PY8eOlWDVAADAmW6rsHPhwgUdOnRIYWFhql+/vjw9PbVq1Srb9P379+vo0aOKjIy85nysVqsCAgLsHgAAwJxc+jDWiy++qM6dOysiIkInT57U+PHj5e7urp49e6p06dLq37+/RowYoaCgIAUEBOi5555TZGQkZ2IBAAAblw47x48fV8+ePXX69GmVL19ezZo10+bNm1W+fHlJ0nvvvSc3Nzd169ZNmZmZateunT766CMnVw0AAFyJS4edefPmXXO6t7e3pk+frunTp9+iigAAwO3mthqzAwAA4CjCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXThJ3p06ercuXK8vb2VqNGjbR161ZnlwQAAFyAKcLO119/rREjRmj8+PHasWOH7r//frVr104pKSnOLg0AADiZKcLOu+++qwEDBqhfv36qWbOmZs6cqVKlSul///d/nV0aAABwsts+7GRlZWn79u2Kioqytbm5uSkqKkqbNm1yYmUAAMAVeDi7gJt16tQp5ebmKiQkxK49JCREv/32W6GvyczMVGZmpu15amqqJCktLa3Y68vLzCj2eRbVtdbHVeuSnFcbdTnudvyMuWpdEp+xK7lqXRKfMUeVxP+vl8/XMIxrdzRucydOnDAkGRs3brRrHzlypNGwYcNCXzN+/HhDEg8ePHjw4MHDBI9jx45dMyvc9nt2ypUrJ3d3dyUnJ9u1JycnKzQ0tNDXjB49WiNGjLA9z8vL05kzZ1S2bFlZLJYSrdcM0tLSVLFiRR07dkwBAQHOLsflsb0cxzZzDNvLMWwvx7nqNjMMQ+fPn1d4ePg1+932YcfLy0v169fXqlWr1KVLF0l/hZdVq1ZpyJAhhb7GarXKarXatQUGBpZwpeYTEBDgUh96V8f2chzbzDFsL8ewvRznitusdOnS1+1z24cdSRoxYoRiYmLUoEEDNWzYUFOnTlV6err69evn7NIAAICTmSLsPPHEE/rPf/6jcePGKSkpSfXq1dPy5csLDFoGAAB3HlOEHUkaMmTIVQ9boXhZrVaNHz++wKFAFI7t5Ti2mWPYXo5heznudt9mFsO43vlaAAAAt6/b/qKCAAAA10LYAQAApkbYAQAApkbYAQAApkbYQZFMnDhRDz74oPz9/RUcHKwuXbpo//79zi7rtvH222/LYrFo2LBhzi7FpZ04cUK9e/dW2bJl5ePjozp16ujnn392dlkuKzc3V6+++qqqVKkiHx8fVa1aVa+//vr17xN0h1i3bp06d+6s8PBwWSwWLV682G66YRgaN26cwsLC5OPjo6ioKP3+++/OKdZFXGubZWdna9SoUapTp458fX0VHh6uPn366OTJk84ruIgIOyiShIQExcbGavPmzVq5cqWys7PVtm1bpaenO7s0l7dt2zbNmjVLdevWdXYpLu3s2bNq2rSpPD09tWzZMu3bt0//+Mc/VKZMGWeX5rImTZqkGTNm6MMPP9Svv/6qSZMmafLkyfrggw+cXZpLSE9P1/3336/p06cXOn3y5MmaNm2aZs6cqS1btsjX11ft2rXTpUuXbnGlruNa2ywjI0M7duzQq6++qh07dmjhwoXav3+/oqOjnVCpg4rjZpy486SkpBiSjISEBGeX4tLOnz9v3HPPPcbKlSuNli1bGs8//7yzS3JZo0aNMpo1a+bsMm4rnTp1Mp5++mm7tkcffdTo1auXkypyXZKMRYsW2Z7n5eUZoaGhxpQpU2xt586dM6xWqzF37lwnVOh6rtxmhdm6dashyThy5MitKeoGsWcHNyQ1NVWSFBQU5ORKXFtsbKw6deqkqKgoZ5fi8r777js1aNBAjz/+uIKDg/XAAw/ok08+cXZZLq1JkyZatWqVDhw4IEn65ZdftH79enXo0MHJlbm+w4cPKykpye53s3Tp0mrUqJE2bdrkxMpuL6mpqbJYLC5/f0nTXEEZt05eXp6GDRumpk2bqnbt2s4ux2XNmzdPO3bs0LZt25xdym3hjz/+0IwZMzRixAiNGTNG27Zt09ChQ+Xl5aWYmBhnl+eSXn75ZaWlpal69epyd3dXbm6u3nzzTfXq1cvZpbm8pKQkSSpwW6GQkBDbNFzbpUuXNGrUKPXs2dPlbg56JcIOHBYbG6s9e/Zo/fr1zi7FZR07dkzPP/+8Vq5cKW9vb2eXc1vIy8tTgwYN9NZbb0mSHnjgAe3Zs0czZ84k7FzF/Pnz9dVXXyk+Pl61atXSzp07NWzYMIWHh7PNUKKys7PVvXt3GYahGTNmOLuc6+IwFhwyZMgQLVmyRGvWrFGFChWcXY7L2r59u1JSUvS3v/1NHh4e8vDwUEJCgqZNmyYPDw/l5uY6u0SXExYWppo1a9q11ahRQ0ePHnVSRa5v5MiRevnll9WjRw/VqVNHTz31lIYPH66JEyc6uzSXFxoaKklKTk62a09OTrZNQ+Hyg86RI0e0cuVKl9+rIxF2UESGYWjIkCFatGiRVq9erSpVqji7JJfWpk0b7d69Wzt37rQ9GjRooF69emnnzp1yd3d3dokup2nTpgUuZ3DgwAFFREQ4qSLXl5GRITc3+69xd3d35eXlOami20eVKlUUGhqqVatW2drS0tK0ZcsWRUZGOrEy15YfdH7//Xf9+OOPKlu2rLNLKhIOY6FIYmNjFR8fr2+//Vb+/v62Y9qlS5eWj4+Pk6tzPf7+/gXGM/n6+qps2bKMc7qK4cOHq0mTJnrrrbfUvXt3bd26VR9//LE+/vhjZ5fmsjp37qw333xTlSpVUq1atfR///d/evfdd/X00087uzSXcOHCBR08eND2/PDhw9q5c6eCgoJUqVIlDRs2TG+88YbuueceValSRa+++qrCw8PVpUsX5xXtZNfaZmFhYXrssce0Y8cOLVmyRLm5ubb/C4KCguTl5eWssq/P2aeD4fYgqdDH7NmznV3abYNTz6/v+++/N2rXrm1YrVajevXqxscff+zsklxaWlqa8fzzzxuVKlUyvL29jbvvvtsYO3askZmZ6ezSXMKaNWsK/d6KiYkxDOOv089fffVVIyQkxLBarUabNm2M/fv3O7doJ7vWNjt8+PBV/y9Ys2aNs0u/JothcKlNAABgXozZAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAYBCWCwWLV682NllACgGhB0ALqVv376yWCx65plnCkyLjY2VxWJR3759i215EyZMUL169YptfgBcD2EHgMupWLGi5s2bp4sXL9raLl26pPj4eFWqVMmJlQG4HRF2ALicv/3tb6pYsaIWLlxoa1u4cKEqVaqkBx54wNaWmZmpoUOHKjg4WN7e3mrWrJm2bdtmm7527VpZLBatWrVKDRo0UKlSpdSkSRPb3dXnzJmjuLg4/fLLL7JYLLJYLJozZ47t9adOnVLXrl1VqlQp3XPPPfruu+9KfuUBFDvCDgCX9PTTT2v27Nm25//7v/+rfv362fV56aWX9K9//UufffaZduzYoWrVqqldu3Y6c+aMXb+xY8fqH//4h37++Wd5eHjY7gr+xBNP6IUXXlCtWrWUmJioxMREPfHEE7bXxcXFqXv37tq1a5c6duyoXr16FZg3ANdH2AHgknr37q3169fryJEjOnLkiDZs2KDevXvbpqenp2vGjBmaMmWKOnTooJo1a+qTTz6Rj4+PPv30U7t5vfnmm2rZsqVq1qypl19+WRs3btSlS5fk4+MjPz8/eXh4KDQ0VKGhofLx8bG9rm/fvurZs6eqVaumt956SxcuXNDWrVtv2TYAUDw8nF0AABSmfPny6tSpk+bMmSPDMNSpUyeVK1fONv3QoUPKzs5W06ZNbW2enp5q2LChfv31V7t51a1b1/ZzWFiYJCklJeW6438uf52vr68CAgKUkpJyU+sF4NYj7ABwWU8//bSGDBkiSZo+ffoNz8fT09P2s8VikSTl5eU59Lr81xbldQBcC4exALis9u3bKysrS9nZ2WrXrp3dtKpVq8rLy0sbNmywtWVnZ2vbtm2qWbNmkZfh5eWl3NzcYqsZgOthzw4Al+Xu7m47JOXu7m43zdfXV4MHD9bIkSMVFBSkSpUqafLkycrIyFD//v2LvIzKlSvr8OHD2rlzpypUqCB/f39ZrdZiXQ8AzkXYAeDSAgICrjrt7bffVl5enp566imdP39eDRo00IoVK1SmTJkiz79bt25auHChWrdurXPnzmn27NnFetFCAM5nMQzDcHYRAAAAJYUxOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNT+H7dy9p2BrVaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming MonthErrors is a dictionary where:\n",
    "# - keys are months\n",
    "# - values are lists where the first element is the mean error and the second element is the standard deviation\n",
    "\n",
    "# Extracting months, mean errors, and standard deviations\n",
    "months = list(MonthErrors.keys())\n",
    "mean_errors = [MonthErrors[key][0] for key in months]\n",
    "std_devs = [MonthErrors[key][1] for key in months]\n",
    "\n",
    "# Specifying that the lower part of the error bar is 0 and the upper part is the standard deviation\n",
    "error_bars = np.array([(0,)*len(std_devs), std_devs])\n",
    "\n",
    "# Creating the bar plot with error bars\n",
    "plt.bar(months, mean_errors, yerr=error_bars, capsize=5)\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Error in MWH\")\n",
    "plt.title(\"Monthly Error with Upper Standard Deviation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the dataframe for mean, lower, and upper bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.drop([\"Predicted Test Output\"], axis = 1, inplace = True)\n",
    "testing_df.insert(1, \"99% lower_bound\", test_uncertainty_df[\"99% lower_bound\"])\n",
    "testing_df.insert(2, \"99.99% lower_bound\", test_uncertainty_df[\"99.99% lower_bound\"])\n",
    "testing_df.insert(3, \"99.999% lower_bound\", test_uncertainty_df[\"99.999% lower_bound\"])\n",
    "testing_df.insert(4, \"mean\", test_uncertainty_df[\"energy_demand_mean\"])\n",
    "testing_df.insert(5, \"99.999% upper_bound\", test_uncertainty_df[\"99.999% upper_bound\"])\n",
    "testing_df.insert(6, \"99.99% upper_bound\", test_uncertainty_df[\"99.99% upper_bound\"])\n",
    "testing_df.insert(7, \"99% upper_bound\", test_uncertainty_df[\"99% upper_bound\"])\n",
    "testing_df.to_csv(\"TestingDataBounds2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.drop([\"Predicted Val Output\"], axis = 1, inplace = True)\n",
    "validation_df.insert(1, \"99% lower_bound\", validation_uncertainty_df[\"99% lower_bound\"])\n",
    "validation_df.insert(2, \"99.99% lower_bound\", validation_uncertainty_df[\"99.99% lower_bound\"])\n",
    "validation_df.insert(3, \"99.999% lower_bound\", validation_uncertainty_df[\"99.999% lower_bound\"])\n",
    "validation_df.insert(4, \"mean\", validation_uncertainty_df[\"energy_demand_mean\"])\n",
    "validation_df.insert(5, \"99.999% upper_bound\", validation_uncertainty_df[\"99.999% upper_bound\"])\n",
    "validation_df.insert(6, \"99.99% upper_bound\", validation_uncertainty_df[\"99.99% upper_bound\"])\n",
    "validation_df.insert(7, \"99% upper_bound\", validation_uncertainty_df[\"99% upper_bound\"])\n",
    "validation_df.to_csv(\"ValidationDataBounds2.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.drop([\"Predicted Train Output\"], axis = 1, inplace = True)\n",
    "training_df.insert(1, \"99% lower_bound\", training_uncertainty_df[\"99% lower_bound\"])\n",
    "training_df.insert(2, \"99.99% lower_bound\", training_uncertainty_df[\"99.99% lower_bound\"])\n",
    "training_df.insert(3, \"99.999% lower_bound\", training_uncertainty_df[\"99.999% lower_bound\"])\n",
    "training_df.insert(4, \"mean\", training_uncertainty_df[\"energy_demand_mean\"])\n",
    "training_df.insert(5, \"99.999% upper_bound\", training_uncertainty_df[\"99.999% upper_bound\"])\n",
    "training_df.insert(6, \"99.99% upper_bound\", training_uncertainty_df[\"99.99% upper_bound\"])\n",
    "training_df.insert(7, \"99% upper_bound\", training_uncertainty_df[\"99% upper_bound\"])\n",
    "training_df.to_csv(\"TrainingDataBounds2.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLrYy9qgxp_C"
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "- Bayesian LSTMs have been able to produce comparable performance to their frequentist counterparts (all else being equal)\n",
    "- Stochastic dropout enables users to approximate the posterior distribution of the target variable, \\\n",
    "and thus construct confidence intervals for each prediction\n",
    "- Bayesian Neural Networks only attempt to account for epistemic model uncertainty and do not necessarily address aleatoric uncertainty\n",
    "- Computational overhead for repeated/multiple Bayesian LSTM predictions at inference to construct confidence intervals represent a potential challenge for real-time inference use-cases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
